---
title: "Accurate sample deconvolution of pooled snRNA-seq using sex-dependent gene expression patterns"
author: "Guy Twa, Robert A. Phillips III, Nathaniel J. Robinson, Jeremy J. Day"
format: 
    html:
        toc: true
        toc-depth: 3
        toc-location: left
        max-width: "1400px"
        embed-resources: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Abstract
Single-nucleus RNA sequencing (snRNA-seq) technology offers unprecedented resolution for studying cell type-specific gene expression patterns. However, snRNA-seq poses high costs and technical limitations, often requiring the pooling of independent biological samples and the loss of individual sample-level data. Deconvolution of sample identity using inherent features would enable the incorporation of pooled barcoding and sequencing protocols, thereby increasing data throughput and analytical sample size without requiring increases in experimental sample size and sequencing costs. In this study, we demonstrate a proof of concept that sex-dependent gene expression patterns can be leveraged for the deconvolution of pooled snRNA-seq data. Using previously published snRNA-seq data from the rat ventral tegmental area, we trained a range of machine learning models to classify cell sex using genes differentially expressed in cells from male and female rats. Models that used sex-dependent gene expression predicted cell sex with high accuracy (93-95%) and outperformed simple classification models using only sex chromosome gene expression (88-90%). The generalizability of these models to other brain regions was assessed using an additional published data set from the rat nucleus accumbens. Within this data set, model performance remained highly accurate in cell sex classification (90-92% accuracy) with no additional re-training. This work provides a model for future snRNA-seq studies to perform sample deconvolution using a two-sex pooled sample sequencing design and benchmarks the performance of various machine learning approaches to deconvolve sample identification from inherent sample features.

## Document details
This file documents the workflow and code used to perfrom the analyses detailed in the manuscript *Accurate sample deconvolution of pooled snRNA-seq using sex-dependent gene expression patterns*. Briefly previously published snRNA-seq data from the rat ventral tegmental area ([Phillips, Tuscher et al., 2022](https://doi.org/10.1016/j.celrep.2022.110616)), containing both male and female samples, was used to train and evaluate machine learning (ML) and non-ML models for cell sex classification. Furthermore, model performance was evaluated on an additional published data set from the rat nucleus accumbens([Phillips et al., 2023](https://doi.org/10.1016/j.mcn.2023.103849)). Data from these previous publications may be accessed via their GEO accessions GSE168156, GSE137763, and GSE222418. 

Each section contains an `R` chunk that corresponds to an independent `.R` script outside of this document. Instead of evaluating these code chunks within this document. `R` scripts were submitted as independent batch jobs to the UAB Cheaha Research Computing cluster using the respective `.sh` Bash script following each `R` chunk.

For clarity, all code chunks are named according to their respective file names outside this document.

:::{.callout-note}
Original file paths and user emails within code chunks have been altered from the original analysis run.
:::

# Analysis
## Data Preparation
We begin analysis with the integrated VTA object previously generated by [Phillips, Tuscher et al., 2022](https://doi.org/10.1016/j.celrep.2022.110616). For this experiment, samples from three rats of the same sex were pooled within each GEM well. This experimental design enables us to train supervised models with a reliable ground-truth for cell sex classifications.

As this dataset was originally processed using an Ensembl gene annotaiton which did not include *Xist*, we need to create a new Seruat object with added *Xist* counts after re-processing this data with a custom annotation file including *Xist*. To maintain consistency with previous analysis of this data, we will keep the same cell type annotations.

### Create VTA Object
```{r filename="1_create_Xist_object.R"}
# Setup ####
## libraries ####
library(Seurat)
library(dplyr)
library(tibble)
library(ggplot2)

## Data ####
# Original Rn7 object (does not have Xist counts)
Rn7_VTA <- readRDS("raw_data/Rn7_VTA.RDS")

# Count matrices for Rn7+Xist alignment
F1_Xist <- Read10X("2020-JD-0044/Rn7_Xist/F1_output_Rn7_Xist/outs/filtered_feature_bc_matrix")
F2_Xist <- Read10X("2020-JD-0044/Rn7_Xist/F2_output_Rn7_Xist/outs/filtered_feature_bc_matrix")
M1_Xist <- Read10X("2020-JD-0044/Rn7_Xist/M1_output_Rn7_Xist/outs/filtered_feature_bc_matrix")
M2_Xist <- Read10X("2020-JD-0044/Rn7_Xist/M2_output_Rn7_Xist/outs/filtered_feature_bc_matrix")

# Create Xist object ####
# Create individual objects for each sample
Fem1  <- CreateSeuratObject(counts = F1_Xist,min.cells = 0,min.features = 0) #5936 nuclei, original: 5940  
Fem2  <- CreateSeuratObject(counts = F2_Xist,min.cells = 0,min.features = 0) #5274 nuclei, original: 5278 
Male1 <- CreateSeuratObject(counts = M1_Xist,min.cells = 0,min.features = 0) #3851 nuclei, original: 3841 
Male2 <- CreateSeuratObject(counts = M2_Xist,min.cells = 0,min.features = 0) #7112 nuclei, original: 7120  
## 22173 total nuclei, original: 22179

# Rename cells to match original Rn7 object
Fem1 <- RenameCells(Fem1, new.names = paste0(colnames(Fem1), "_1"))
Fem2 <- RenameCells(Fem2, new.names = paste0(colnames(Fem2), "_2"))
Male1 <- RenameCells(Male1, new.names = paste0(colnames(Male1), "_3"))
Male2 <- RenameCells(Male2, new.names = paste0(colnames(Male2), "_4"))

# Verify that new cell names match a subset of the original Rn7 object
Fem1_cells <- Cells(Fem1)[Cells(Fem1) %in% c(Rn7_VTA@meta.data %>% filter(GEM_Well == "Fem1") %>% rownames())] #5930 nuclei
Fem2_cells <- Cells(Fem2)[Cells(Fem2) %in% c(Rn7_VTA@meta.data %>% filter(GEM_Well == "Fem2") %>% rownames())] #5274 nuclei
Male1_cells <- Cells(Male1)[Cells(Male1) %in% c(Rn7_VTA@meta.data %>% filter(GEM_Well == "Male1") %>% rownames())] #3839 nuclei
Male2_cells <- Cells(Male2)[Cells(Male2) %in% c(Rn7_VTA@meta.data %>% filter(GEM_Well == "Male2") %>% rownames())] #7106 nuclei
Xist_cells <- c(Fem1_cells, Fem2_cells, Male1_cells, Male2_cells)
## 22149 total nuclei, original final object: 22170

# Extract raw Xist counts from Xist objects
Fem1_Xist <- LayerData(Fem1, "counts", cells = Fem1_cells, features = "Xist")
Fem2_Xist <- LayerData(Fem2, "counts", cells = Fem2_cells, features = "Xist")
Male1_Xist <- LayerData(Male1, "counts", cells = Male1_cells, features = "Xist")
Male2_Xist <- LayerData(Male2, "counts", cells = Male2_cells, features = "Xist")
## Merge Xist counts into a single matrix
Xist_counts <- cbind(Fem1_Xist, Fem2_Xist, Male1_Xist, Male2_Xist)

# Extract raw counts from Rn7 object
Rn7_VTA_Xist <- LayerData(Rn7_VTA, "counts", cells = Xist_cells)
## Merge Xist counts with Rn7 counts
Rn7_VTA_Xist <- rbind(Rn7_VTA_Xist, Xist_counts)

# Create Object
Rn7_VTA_Xist_obj <- CreateSeuratObject(counts = Rn7_VTA_Xist, min.cells = 0, min.features = 0)
## Re-add metadata
Rn7_VTA_Xist_obj$GEM_Well <- Rn7_VTA@meta.data[rownames(Rn7_VTA_Xist_obj@meta.data), "GEM_Well"]
Rn7_VTA_Xist_obj$Sex <- Rn7_VTA@meta.data[rownames(Rn7_VTA_Xist_obj@meta.data), "Sex"]
Rn7_VTA_Xist_obj$CellType <-  Rn7_VTA@meta.data[rownames(Rn7_VTA_Xist_obj@meta.data), "CellType"]
## Normalize data
Rn7_VTA_Xist_obj <- NormalizeData(Rn7_VTA_Xist_obj, normalization.method = "LogNormalize", scale.factor = 10000)
## Scale data
Rn7_VTA_Xist_obj <- ScaleData(Rn7_VTA_Xist_obj, verbose = FALSE)

# Save object ####
saveRDS(Rn7_VTA_Xist_obj, file = "processed_data/Rn7_Xist_VTA.RDS")

# sessionInfo ####
sessionInfo()
```

```{bash filename="1_create_Xist_object.sh"}
#!/bin/bash
#
#SBATCH --job-name=1_create_Xist_object
#SBATCH --output=logs/1_create_Xist_object.out
#SBATCH --error=logs/1_create_Xist_object.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/1_create_Xist_object.R
```

### Create Testing and Training Partitions
```{r filename="2_create_splits.R"}
# Setup ####
## libraries ####
library(Seurat)
library(dplyr)
library(caret)

## Data ####
Rn7_VTA <- readRDS("processed_data/Rn7_Xist_VTA.RDS")

# Create splits ####
Rn7_VTA$CellType_Sex <- paste(Rn7_VTA$CellType,Rn7_VTA$Sex,sep = "_")


## create partition of training and test data
trainingIndex <- createDataPartition(Rn7_VTA$CellType_Sex, p = .7, 
                                     list = FALSE, 
                                     times = 1)

training.df <- Rn7_VTA@meta.data[trainingIndex,]
testing.df <- Rn7_VTA@meta.data[-trainingIndex,]

training_cells <- rownames(training.df)
testing_cells <- rownames(testing.df)

## make summary table of the number and proportion of cell type and sex 
summary.df <- table(Rn7_VTA$CellType_Sex) %>% as.data.frame()
summary.df$prop <- summary.df$Freq/sum(summary.df$Freq)

summary.df$N_cells_train <- data.frame(table(training.df$CellType_Sex))$Freq
summary.df$Proportion_train <- summary.df$N_cells_train/sum(summary.df$N_cells_train)

summary.df$N_cells_test <- data.frame(table(testing.df$CellType_Sex))$Freq
summary.df$Proportion_test <- summary.df$N_cells_test/sum(summary.df$N_cells_test)

## make subset objects
### make cell name a metadata column
Rn7_VTA@meta.data$CellName <- rownames(Rn7_VTA@meta.data)

Rn7_VTA_training <- subset(Rn7_VTA, subset = CellName %in% training_cells)
Rn7_VTA_testing <- subset(Rn7_VTA, subset = CellName %in% testing_cells)

# Save outputs ####
## save summary table
write.csv(summary.df, file = "processed_data/2_create_splits/CellType_Sex_split_summary.csv")

## save cell split vectors
saveRDS(training_cells, file = "processed_data/2_create_splits/traincell_vector.RDS")
saveRDS(testing_cells, file = "processed_data/2_create_splits/testcell_vector.RDS")

## save Rn7 training and testing objects 
saveRDS(Rn7_VTA_training, file = "processed_data/2_create_splits/Rn7_VTA_training.RDS")
saveRDS(Rn7_VTA_testing, file = "processed_data/2_create_splits/Rn7_VTA_testing.RDS")

# sessionInfo ####
sessionInfo()
```

```{bash filename="2_create_splits.sh"}
#!/bin/bash
#
#SBATCH --job-name=2_create_splits
#SBATCH --output=logs/2_create_splits.out
#SBATCH --error=logs/2_create_splits.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/2_create_splits.R
```

## Feature Selection
When building our model, we need to determine what features (in this case, genes or transcripts) will be included as predictors of our outcome variable (in this case, sex). While intuition may be that more data is always better, in reality it is often the case that having a few powerful predictive features lead to better performance than many weak predictors. This is in part due to the fact that predictors with weak or no relation to the outcome variable will contribute noise and hinder prediction.

There are a number of methods for feature selection. For this analysis we use differential expression analysis to identify genes with significant sex dependent expression, and further narrow this using the wrapper feature selection method `Boruta` to find important predictors. Boruta will create "shadow" features by shuffling the values of our real features and iteratively building random forest classifiers with the combined set of real and shadow features. After each iteration, it will compare the importance scores of each feature and "reject" or "confirm" the real features which are significantly less or more important than the best performing shadow feature.

### Differential Gene Expression
Differentially expressed genes (DEGs) between male and female cells within the VTA snRNA-seq training data were determined for each cell type by the Wilcoxon Rank Sum test implemented in the `FindMarkers()` function from `Seurat` with default parameters. Significant DEGs were identified as those with Bonferroni-adjusted p-values < 0.05 in at least one cell type.

```{r filename="3_feature_selection_DEGs.R"}
# Setup ####
## libraries ####
library(Seurat)
library(tidyverse)

## Data ####
# training partition
Rn7_VTA <- readRDS("processed_data/2_create_splits/Rn7_VTA_training.RDS")
### Rn7 gene names
Rn7_gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
Rn7_gtf <- as.data.frame(Rn7_gtf)

# Differential Expression ####
# Set identities for testing
Idents(Rn7_VTA) <- Rn7_VTA$CellType_Sex

# Find Markers
Sex_DEGs <- vector(mode = "list",length = 16)
names(Sex_DEGs) <- levels(Rn7_VTA$CellType)
for(i in names(Sex_DEGs)){
  Sex_DEGs[[i]] <- FindMarkers(object = Rn7_VTA,
                               ident.1 = paste0(i,"_Female"),
                               ident.2 = paste0(i,"_Male"))
}

# Format results ####
# flatten list
Sex_DEGs <- do.call(what = rbind,Sex_DEGs)

# Create an ID column that is the rownames
Sex_DEGs$ID <- rownames(Sex_DEGs)

# Add gene names and cluster
Sex_DEGs <- separate(Sex_DEGs, col = ID, into = c("Cluster", "GeneName"), sep = "\\.", remove = FALSE, extra = "merge")

# Create subset for significant DEGs
Sex_DEGs.significant <- subset(Sex_DEGs,subset=(p_val_adj < 0.05))

# Build a table of the frequency by which the gene is differentially expressed by sex
Sex_DEGs_Freq <- as.data.frame(table(Sex_DEGs.significant$GeneName))

# Get chromosomes of all Sex_DEGs
for(i in 1:nrow(Sex_DEGs_Freq)){
  if(is.na(Rn7_gtf[which(Rn7_gtf$gene_name  %in% as.character(Sex_DEGs_Freq[i,"Var1"]))[1],"gene_name"]) == TRUE){
    Sex_DEGs_Freq[i,"Chr"] <- as.character(Rn7_gtf[which(Rn7_gtf$gene_id  %in% as.character(Sex_DEGs_Freq[i,"Var1"]))[1],
                                                   "seqnames"])
  }else{
    Sex_DEGs_Freq[i,"Chr"] <- Rn7_gtf[which(Rn7_gtf$gene_name  %in% as.character(Sex_DEGs_Freq[i,"Var1"]))[1],"seqnames"]
  }
}

# Get the mean fold change of the genes
Sex_DEGs_Freq$Mean_logFC <- NA
for(i in 1:nrow(Sex_DEGs_Freq)){
  if(Sex_DEGs_Freq[i,"Freq"]>1){
    Sex_DEGs_Freq[i,"Mean_logFC"] <- mean(subset(Sex_DEGs.significant,subset=(GeneName == as.character(Sex_DEGs_Freq[i,"Var1"])))$avg_log2FC)
  }else{
    Sex_DEGs_Freq[i,"Mean_logFC"] <- subset(Sex_DEGs.significant,subset=(GeneName == as.character(Sex_DEGs_Freq[i,"Var1"])))$avg_log2FC
  }
}


# Pull counts matrix for significant DEGs ####
count_data_Full <- as.data.frame(t(as.matrix(GetAssayData(object = Rn7_VTA,slot = "data",assay = "RNA"))))

# check if rownames are in same order as the identities vector 
all(names(Idents(Rn7_VTA)) == rownames(count_data_Full)) #TRUE 

# create a new column in the count_data_full for identity
count_data_Full$Identity <- as.factor(Rn7_VTA$Sex)

# convert identitity to binary code. 
count_data_Full$Identity_bin <- ifelse(count_data_Full$Identity  == "Female",
                                       1, #Females are 1
                                       0) #Males are 0

# create a subset of count data full containing all of the Sex_DEGs
count_data_subset <- count_data_Full[,c(as.character(Sex_DEGs_Freq$Var1),"Identity_bin")]


# Save outputs ####
write.csv(Sex_DEGs,
          file = "processed_data/3_feature_selection_DEGs/DEGs_sex_cluster_VTA_full.csv", row.names = F)
write.csv(Sex_DEGs.significant, 
          file = "processed_data/3_feature_selection_DEGs/DEGs_sex_cluster_VTA_sig.csv", row.names = F)

write.table(x         = Sex_DEGs_Freq,
            file      = "processed_data/3_feature_selection_DEGs/DEGsbySexbyCluster_VTA.txt",
            sep       = "\t",
            col.names = TRUE,
            row.names = FALSE,
            quote     = FALSE)

saveRDS(object = count_data_subset,
        file = "processed_data/3_feature_selection_DEGs/count_data_subset.RDS")

# Session info ####
sessionInfo()
```

```{bash filename="3_feature_selection_DEGs.sh"}
#!/bin/bash
#
#SBATCH --job-name=3_feature_selection_DEGs
#SBATCH --output=logs/3_feature_selection_DEGs.out
#SBATCH --error=logs/3_feature_selection_DEGs.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/3_feature_selection_DEGs.R
```

### Boruta
The Boruta feature selection algorithm further refined the set of significant DEGs by identifying genes with significant importance for cell sex classification within the VTA training partition. Importance was determined by iteratively comparing the importance, measured as Z-scores of mean decrease accuracy measure, of real genes to a set of null “shadow features” constructed from shuffled gene counts using the `Boruta()` function from the Boruta package (version 8.0.0). At each iteration, genes with significantly lower scores are rejected and removed while genes with significantly higher scores are confirmed and retained. After 3000 iterations, final decisions of genes with tentative importance were made using the `TentativeRoughFix()` Boruta function. The final set of genes with confirmed importance was used as predictive variables for cell sex classification models.
```{r filename="4_feature_selection_Boruta.R"}
# Setup ####
## libraries ####
library(Seurat)
library(Boruta)
library(dplyr)

## set seed ####
set.seed(1234)

## data ####
# training counts
training <- readRDS("processed_data/3_feature_selection_DEGs/count_data_subset.RDS")
# testing counts
testing <- readRDS("processed_data/2_create_splits/Rn7_VTA_testing.RDS")

# Feature Selection ####
VTA_Boruta <- Boruta(Identity_bin ~ ., data = training, maxRuns = 3000, doTrace = 2)
# Save output
saveRDS(VTA_Boruta,"processed_data/4_feature_selection_Boruta/VTA_Boruta_max3000.RDS")

# Post Selection Processing ####
# print summary
VTA_Boruta

# perform rough fix 
VTA_Boruta <- TentativeRoughFix(VTA_Boruta)
VTA_Boruta

# extract decisions for features
VTA_Boruta_decision <- VTA_Boruta$finalDecision %>% data.frame()
colnames(VTA_Boruta_decision) <- c("finalDecision")
VTA_Boruta_decision$variable <- rownames(VTA_Boruta_decision)
VTA_Boruta_decision <- VTA_Boruta_decision %>% select(variable, finalDecision) # reorder for my sanity

# Get column names with confirmed values
confirmed_columns <- VTA_Boruta_decision$variable[VTA_Boruta_decision$finalDecision == "Confirmed"]

# Create count data subsets ####
## Create training count data subsets
training_important <- training[, colnames(training) %in% confirmed_columns]
### Add identity bin back in
training_important$Identity_bin <- training$Identity_bin

## Create testing count data subset
count_data <- as.data.frame(t(as.matrix(GetAssayData(object = testing,slot = "data",assay = "RNA"))))
### check if rownames are in same order as the identities vector 
all(names(Idents(testing)) == rownames(count_data)) #TRUE 
### Now just create a new column in the count_data_full for identity
count_data$Identity <- as.factor(testing$Sex)
### Convert identitity to binary code. 
count_data$Identity_bin <- ifelse(count_data$Identity  == "Female",
                                  1, #Females are 1
                                  0) #Males are 0
### Create a subset of count data containing the same features as the training set
test_important <- count_data[,colnames(count_data) %in% colnames(training_important)]

# Save outputs ####
## Boruta variable final decisions
write.csv(VTA_Boruta_decision, file = "processed_data/4_feature_selection_Boruta/Boruta_final_decisions.csv", row.names = F)
## training and testing count data frames
write.csv(training_important, file = "processed_data/4_feature_selection_Boruta/training_count_data.csv")
write.csv(test_important, file = "processed_data/4_feature_selection_Boruta/test_count_data.csv")

# sessionInfo ####
sessionInfo()

# Session Info ####
sessionInfo()
```

```{bash filename="4_feature_selection_Boruta.sh"}
#!/bin/bash
#
#SBATCH --job-name=4_feature_selection_Boruta
#SBATCH --output=logs/4_feature_selection_Boruta.out
#SBATCH --error=logs/4_feature_selection_Boruta.err
#SBATCH --ntasks=1
#SBATCH --partition=long
#SBATCH --time=150:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/4_feature_selection_Boruta.R
```


## Model Training
To train cell sex prediction models, models were fitted using the VTA training partition log normalized gene counts as predictor variables and cell sex as the outcome variable. The Xist model made binary female or male cell sex predictions based on the presence or absence of *Xist* counts. Reciprocally, the Chromosome Y classifier made binary male or female cell sex predictions based on the presence or absence of counts from any gene on the Y chromosome. The logistic regression model was fit to the training data with the `glm()` function from the `stats` package (version 4.2.0). To assess training for a range of hyperparameters the random forest, support vector machine, and multilayer perceptron models were trained with the `train()` function of the `caret` package (version 6.0-94). Training parameters were set to output cell sex class probabilities and perform 3x repeated 10-fold cross-validation using `trainControl()` with parameters `method = "repeatedcv", number = 10, repeats = 3, classProbs = T, allowParallel = T`. Ranges for model hyperparameters for each model were specified using tuning grids defined for each model, described in detail below. Model accuracy was used to select the optimal configuration for each model.

### Logistic Regression
The logistic regression model was fit to the training data with the `glm()` function from the `stats` package (version 4.2.0) with cell sex as the outcome variable, all ‘Confirmed’ important genes as predictor variables, and the family parameter set to “binomial”.

```{r filename="5_training_logistic_regression.R"}
# Set up ####
## libraries
library(caret)
library(tidyverse)

## set seed
set.seed(1234)

## load data
### training dataframe
training <- read.csv("processed_data/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- as.factor(training$Identity_bin)

# Train Model ####
lr_model <- glm(Identity_bin ~ .,
                data = training,
                family = "binomial")
# Summary
summary(lr_model)

# Write out files ####
saveRDS(lr_model, file = "processed_data/5_training_logistic_regression/lr_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="5_training_logistic_regression.sh"}
#!/bin/bash
#
#SBATCH --job-name=5_training_logistic_regression
#SBATCH --output=logs/5_training_logistic_regression.out
#SBATCH --error=logs/5_training_logistic_regression.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/5_training_logistic_regression.R
```

### Random Forest
The random forest model was trained with `method = "rf"` and a constant number of 1000 trees `ntrees = 1000` as `train()` function parameters. To tune the number of variables randomly sampled at each split, the custom tuning grid assessed a range of “mtry” values from 2-334 by steps of 12. The final optimal model selected for accuracy used `ntree = 1000`, and `mtry = 74`.

```{r filename="6_training_random_forest.R"}
# Setup ####
library(randomForest)
library(ROCR)
library(caret)
library(tidyverse)
library(doParallel)

## set seed
set.seed(1234)
## setup parallel
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

## load data
### training dataframe
training <- read.csv("processed_data/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- recode(training$Identity_bin, `0` = "Male", `1` = "Female")
training$Identity_bin <- factor(training$Identity_bin, levels = c("Male", "Female"))

# Train Model ####
mtry_values <- seq(from = 2, to = 334, by = 12)

# Generate all combinations
tune.grid <- expand.grid(mtry = mtry_values)

train.ctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           classProbs = T,
                           allowParallel = T)
rf_model <- train(Identity_bin ~ ., data = training, 
                  method = "rf",
                  trControl = train.ctrl,
                  tuneGrid = tune.grid,
                  ntree = 1000)
rf_model

stopCluster(cl)

# Write out files ####
saveRDS(rf_model, file = "processed_data/6_training_random_forest/rf_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="6_training_random_forest.sh"}
#!/bin/bash
#
#SBATCH --job-name=6_training_random_forest
#SBATCH --output=logs/6_training_random_forest.out
#SBATCH --error=logs/6_training_random_forest.err
#SBATCH --ntasks=1
#SBATCH --partition=medium
#SBATCH --time=50:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/6_training_random_forest.R
```

### Support Vector Machine
The support vector machine (SVM) model was trained with `method = "svmRadial"` as a parameter of the `train()` function, to specify an SVM model with a radial basis function. A custom tuning grid of hyperparameters specifying “sigma” values from 0.0001 to 0.1, where steps increase by a factor of 10 with each subsequent term, and C values from 0.1 to 10 (0.1,0.2,0.5,1,1.5,2,5,10), was utilized for model training. The final optimal model selected for accuracy used `sigma = 1e-3` and `C = 5`.

```{r filename="7_training_svm.R"}
# Setup ####
library(kernlab)
library(ROCR)
library(caret)
library(tidyverse)
library(doParallel)

## set seed
set.seed(1234)
## setup parallel
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

## load data
### training data frame
training <- read.csv("processed_data/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- recode(training$Identity_bin, `0` = "Male", `1` = "Female")
training$Identity_bin <- factor(training$Identity_bin, levels = c("Male", "Female"))

# Train Model ####
## Create vectors for sigma and C
sigma_values <- c(0.0001,0.001,0.01,0.1)
C_values <- c(c(0.1,0.2,0.5,1,1.5,2,5,10))

## Generate training grid
train.grid <- expand.grid(sigma = sigma_values, C = C_values)

## create training control parameters
train.ctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           classProbs = T,
                           allowParallel = T)

svm_model <- train(Identity_bin ~ ., data = training, 
                   method = "svmRadial",
                   verbose = T,
                   trControl = train.ctrl,
                   tuneGrid = train.grid)

svm_model

stopCluster(cl)
# Write out files ####
saveRDS(svm_model, file = "processed_data/7_training_svm/svm_rad_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="7_training_svm.sh"}
#!/bin/bash
#
#SBATCH --job-name=7_training_svm
#SBATCH --output=logs/7_training_svm.out
#SBATCH --error=logs/7_training_svm.err
#SBATCH --ntasks=1
#SBATCH --partition=long
#SBATCH --time=72:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/7_training_svm.R
```

### Multi-layer Perceptron
A multi-layer perceptron with weight decay was trained with `method = "mlpWeightDecayML"` as `train()` function parameters. Model hyperparameters for training were tuned using a custom tuning grid specifying ranges for the number of nodes for each layer 1 (1,5,10,15,20), layer 2 (0,2,5,8,10), layer 3 (0,1,2,4,5), and weight decay `decay` values (0,0.05,0.1,0.15,0.2). Only hyperparameter configurations with decreasing nodes in successive layers were evaluated. The final optimal model selected for accuracy was trained using `layer1 = 20`, `layer2 = 10`, `layer3 = 4`, and `decay = 0`.

```{r filename="8_training_mlp.R"}
# Set up ####
## libraries
library(RSNNS)
library(ROCR)
library(caret)
library(tidyverse)
library(doParallel)

## set seed
set.seed(1234)
## setup parallel
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

## load data
### training dataframe
training <- read.csv("processed_data/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- recode(training$Identity_bin, `0` = "Male", `1` = "Female")
training$Identity_bin <- factor(training$Identity_bin, levels = c("Male", "Female"))

# Train Model ####
# Create vectors for layer1, layer2, and decay
layer1_values <- c(1,seq(from = 5, to = 20, by = 5))
layer2_values <- c(0, round(layer1_values / 2)) %>% unique()
layer3_values <- round(layer2_values / 2)  
decay_values <- seq(from = 0, to = 0.2, by = 0.05)

# Generate all combinations
train.grid <- expand.grid(layer1 = layer1_values,
                          layer2 = layer2_values,
                          layer3 = layer3_values,
                          decay = decay_values)

# Filter rows where layer2 is smaller than layer1
train.grid <- train.grid[train.grid$layer2 < train.grid$layer1, ]

# Filter rows where layer3 is smaller than layer2
train.grid <- train.grid[train.grid$layer3 < train.grid$layer2, ]

train.ctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           classProbs = T,
                           allowParallel = T)
mlp_model <- caret::train(Identity_bin ~ ., data = training, 
                          method = "mlpWeightDecayML",
                          trControl = train.ctrl,
                          tuneGrid = train.grid)

mlp_model

stopCluster(cl)
# Write out files ####
saveRDS(mlp_model, file = "processed_data/8_training_mlp/mlpwdml_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="8_training_mlp.sh"}
#!/bin/bash
#
#SBATCH --job-name=8_training_mlp
#SBATCH --output=logs/8_training_mlp.out
#SBATCH --error=logs/8_training_mlp.err
#SBATCH --ntasks=1
#SBATCH --partition=medium
#SBATCH --time=50:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/8_training_mlp.R
```


## Model Evaluation
Model performance was evaluated using the VTA testing partition and the NAc dataset. Neuronal and non-neuronal models were evaluated using respective subsets of the VTA testing data partition. Overall model classification accuracy was calculated as the number of correct classifications divided by the number of total classifications made. For all models, the receiver operating characteristic (ROC) curve and the area under the ROC (AUC-ROC) were used to evaluate the trade-off of sensitivity and specificity rates. ROC curve and AUC values were calculated using the `roc()` function of the `pROC` package in R. True-positive and false-positive rates were calculated using males as the “positive” class.

### VTA Overall Evaluation
verall model performance of models trained with the VTA training partition was assessed first using the VTA testing partition. Models were evaluated based on their overall accuracy (proportion of correct classifications), as well as sensitivity and speciticity with the receiver operating characteristic (ROC) curve and the area under the ROC (AUC-ROC). In the evaluation of sensitivity and specificity we use male cells as the "positive" class, however it would be equally valid to use females as the "positive" class. The important thing is that this choice of "positive" class remains consistent for all model evaluations.

```{r filename="9_evaluation_overall.R"}
# Setup ####
## libraries
library(Seurat)
library(randomForest)
library(kernlab)
library(RSNNS)
library(caret)
library(ROCR)
library(pROC)
library(ggplot2)
library(dplyr)
library(tidyr)

## set seed
set.seed(1234)

## data
### gene chromosome data
Rn7.gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
Rn7.gtf <- as.data.frame(Rn7.gtf)

### models
lr_model <- readRDS("processed_data/5_training_logistic_regression/lr_model.RDS")
rf_model <- readRDS("processed_data/6_training_random_forest/rf_model.RDS")
svm_model <- readRDS("processed_data/7_training_svm/svm_rad_model.RDS")
mlp_model <- readRDS("processed_data/8_training_mlp/mlpwdml_model.RDS")

### testing data
#### testing object
testing_obj <- readRDS("processed_data/2_create_splits/Rn7_VTA_testing.RDS")
#### count matrix
testing <- read.csv("processed_data/4_feature_selection_Boruta/test_count_data.csv", row.names = 1)
#### make character ID bin
testing$Identity_bin_char <- recode(testing$Identity_bin, `0` = "Male", `1` = "Female")
testing$Identity_bin_char <- factor(testing$Identity_bin_char, levels = c("Male", "Female"))
#### make ID bin a factor
testing$Identity_bin <- as.factor(testing$Identity_bin)

# Baseline Classifiers ####
## chr Y
y.count <- function(srat.object){
  # load gene expression count data
  srat.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA"))))
  
  # load gene annotations
  Rn7.gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
  Rn7.gtf <- as.data.frame(Rn7.gtf)
  
  # select Y chromosome genes
  y.genes <- Rn7.gtf %>% #from Rn7 gene annotations
    filter(seqnames == "Y") %>% #filter for chrY only
    select(gene_id, gene_name) %>% #select gene ids and names
    mutate(gene_name = coalesce(gene_name, gene_id)) %>% #replace NA name values with gene ID
    pull(gene_name) %>% #pull gene name values
    unique() #only unique values, returns 27 genes
  
  # create cumulative expresion of Y genes
  y.counts <- srat.counts %>%
    select(any_of(y.genes)) %>%
    rowSums()

  return(y.counts)
}
## Xist
Xist.count <- function(srat.object){
  # load gene expression count data
  Xist.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA")))) %>%
    pull("Xist")
  
  return(Xist.counts)
}

# Predictions ####
## logistic regression
lr_prediction <- predict(lr_model,testing[,1:(ncol(testing)-2)], type = "response")
## support vector machine
svm_prediction <- predict(svm_model,testing[,1:(ncol(testing)-2)], type = "prob")
## random forrest
rf_prediction <- predict(rf_model,testing[,1:(ncol(testing)-2)], type = "prob")
## multi-layer perceptron
mlp_prediction <- predict(mlp_model,testing[,1:(ncol(testing)-2)], type = "prob")
## chrY expression based prediction
chrY_prediction <- y.count(testing_obj)
## Xist expression based prediction
Xist_prediction <- Xist.count(testing_obj)


# ROC curves ####
## calculate ROC
lr_roc <- roc(testing$Identity_bin,lr_prediction, levels = c(1,0))
svm_roc <- roc(testing$Identity_bin_char, svm_prediction[,2], levels = c("Female", "Male"))
rf_roc <- roc(testing$Identity_bin_char, rf_prediction[,2], levels = c("Female", "Male"))
mlp_roc <- roc(testing$Identity_bin_char, mlp_prediction[,2], levels = c("Female", "Male"))
chrY_roc <- roc(testing$Identity_bin_char, chrY_prediction, levels = c("Female", "Male"))
Xist_roc <- roc(testing$Identity_bin_char, Xist_prediction, levels = c("Female", "Male"), direction = ">")

## plot ROC curves
g <- ggroc(data = list(`Chr Y` = chrY_roc,
                       `Xist` = Xist_roc,
                       `Logistic Regression` = lr_roc,
                       `SVM` = svm_roc,
                       `Random Forest` = rf_roc,
                       `MLP` = mlp_roc), legacy.axes = TRUE) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(color = "Model") +
  theme_bw()
ggsave(filename = "plots/9_evaluation_overall/ROC_curves.pdf",
       plot = g + theme(text = element_text(size = 20)),
       height = 10,
       width = 12,
       device = "pdf")

## save AUC values
auc.table <- data.frame(AUC = c(chrY_roc[["auc"]] %>% as.numeric(),
                                Xist_roc[["auc"]] %>% as.numeric(),
                                lr_roc[["auc"]] %>% as.numeric(),
                                svm_roc[["auc"]] %>% as.numeric(),
                                rf_roc[["auc"]] %>% as.numeric(),
                                mlp_roc[["auc"]] %>% as.numeric()))
rownames(auc.table) <- c("Chr Y",
                         "Xist",
                         "Logistic Regression",
                         "SVM",
                         "Random Forest",
                         "MLP")
write.csv(auc.table, "processed_data/9_evaluation_overall/AUCs_table.csv")

# Confusion Matrices ####
## make precitions using threshold
svm_prediction$class <- ifelse(svm_prediction$Female >0.5, "Female", "Male")
svm_prediction$class <- factor(svm_prediction$class, levels = c("Male", "Female"))

rf_prediction$class <- ifelse(rf_prediction$Female >0.5, "Female", "Male")
rf_prediction$class <- factor(rf_prediction$class, levels = c("Male", "Female"))

mlp_prediction$class <- ifelse(mlp_prediction$Female >0.5, "Female", "Male")
mlp_prediction$class <- factor(mlp_prediction$class, levels = c("Male", "Female"))

lr_prediction <- ifelse(lr_prediction >0.5, 1, 0)
lr_prediction <- as.factor(lr_prediction)

chrY_class <- ifelse(chrY_prediction > 0.5, "Male", "Female")
chrY_class <- factor(chrY_class, levels = c("Male", "Female"))

Xist_class <- ifelse(Xist_prediction < 0.5, "Male", "Female")
Xist_class <- factor(Xist_class, levels = c("Male", "Female"))


## make confusion matrices
svm_confusion <- caret::confusionMatrix(svm_prediction$class,testing$Identity_bin_char)
rf_confusion <- caret::confusionMatrix(rf_prediction$class,testing$Identity_bin_char)
mlp_confusion <- caret::confusionMatrix(mlp_prediction$class,testing$Identity_bin_char)
lr_confusion <- caret::confusionMatrix(lr_prediction, testing$Identity_bin)
chrY_confusion <- caret::confusionMatrix(chrY_class, testing$Identity_bin_char)
Xist_confusion <- caret::confusionMatrix(Xist_class, testing$Identity_bin_char)

## print confusion matrices to log
print("SVM confusion Matrix: ")
svm_confusion
cat("\n")

print("Random Forest confusion Matrix: ")
rf_confusion
cat("\n")

print("MLP confusion matrix: ")
mlp_confusion
cat("\n")

print("Logistic Regression confusion matrix: ")
lr_confusion
cat("\n")

print("Chr Y confusion matrix: ")
chrY_confusion
cat("\n")

print("Xist confusion matrix: ")
Xist_confusion
cat("\n")

## make accuracy table
acc.table <- data.frame(Accuracy = c(chrY_confusion[["overall"]][["Accuracy"]],
                                     Xist_confusion[["overall"]][["Accuracy"]],
                                     lr_confusion[["overall"]][["Accuracy"]],
                                     svm_confusion[["overall"]][["Accuracy"]],
                                     rf_confusion[["overall"]][["Accuracy"]],
                                     mlp_confusion[["overall"]][["Accuracy"]]))
rownames(acc.table) <- c("Chr Y",
                         "Xist",
                         "Logistic Regression",
                         "SVM",
                         "Random Forest",
                         "MLP")
write.csv(acc.table, "processed_data/9_evaluation_overall/Accuracy_table.csv")

## stacked bar plot of prediction accuracies
### make list of confusion matrices
confusion.list <- list(ChrY = chrY_confusion,
                       Xist = Xist_confusion,
                       `Logistic Regression` = lr_confusion,
                       SVM = svm_confusion,
                       `Random Forest` = rf_confusion,
                       MLP = mlp_confusion)

### extract values to data frame with values for reference_prediction
confusion.df <- data.frame(model = c("Chr Y","Xist", "Logistic Regression", "SVM", "Random Forest", "MLP"),
                           Male_correct = lapply(confusion.list, function(x){x[["table"]][1,1]}) %>% unlist(),
                           Female_incorrect = lapply(confusion.list, function(x){x[["table"]][1,2]}) %>% unlist(),
                           Male_incorrect = lapply(confusion.list, function(x){x[["table"]][2,1]}) %>% unlist(),
                           Female_correct = lapply(confusion.list, function(x){x[["table"]][2,2]}) %>% unlist())

### convert to long format and split reference level and prediction
confusion.df.long <- confusion.df %>%
  pivot_longer(cols = Male_correct:Female_correct,
               names_to = "prediction",
               values_to = "count") %>%
  separate(col = prediction,
           into = c("reference","prediction"),
           sep = "_")

### convert variables to factors
confusion.df.long <- confusion.df.long %>% mutate(reference = factor(reference, levels = c("Male", "Female")),
                                                  prediction = factor(prediction, levels = c("incorrect","correct")),
                                                  model = factor(model, levels = rev(c("Chr Y","Xist", "Logistic Regression", "SVM", "Random Forest", "MLP"))))

### create stacked bar plot of predictions split by sex
confusion.plot <- ggplot(data = confusion.df.long, mapping = aes(x=model, y=count, fill=prediction)) + 
  scale_fill_manual(values = c(correct = "#00A651", incorrect = "#000000")) +
  geom_bar(position="fill", stat="identity") +
  facet_wrap( ~ reference) +
  theme_bw() +
  coord_flip() +
  labs(title = "Confuson plot", x = "Model", y = "Proportion") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())

### save
ggsave(plot = confusion.plot,
       file = "plots/9_evaluation_overall/confusionplot.pdf",
       height = 7,
       width = 10,
       device = "pdf")

# sessionInfo
sessionInfo()
```

```{bash filename="9_evaluation_overall.sh"}
#!/bin/bash
#
#SBATCH --job-name=9_evaluation_overall
#SBATCH --output=logs/9_evaluation_overall.out
#SBATCH --error=logs/9_evaluation_overall.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@mail.edu

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/9_evaluation_overall.R
```


### VTA Cell Type-Specific Evaluation
We further examine model performance with respect to the neuronal and non-neuronal cell populations of our dataset. To conduct these cell type-specific evaluations, we calculate performance metrics for each cell type subset of interest.

```{r filename="10_evaluation_celltype_specific.R"}
# Setup ####
## libraries
library(Seurat)
library(randomForest)
library(kernlab)
library(RSNNS)
library(caret)
library(ROCR)
library(pROC)
library(ggplot2)
library(dplyr)
library(tidyr)

## set seed
set.seed(1234)

### models
lr_model <- readRDS("processed_data/5_training_logistic_regression/lr_model.RDS")
rf_model <- readRDS("processed_data/6_training_random_forest/rf_model.RDS")
svm_model <- readRDS("processed_data/7_training_svm/svm_rad_model.RDS")
mlp_model <- readRDS("processed_data/8_training_mlp/mlpwdml_model.RDS")

### testing data
#### testing object
testing_obj <- readRDS("processed_data/2_create_splits/Rn7_VTA_testing.RDS")
#### count matrix
testing <- read.csv("processed_data/4_feature_selection_Boruta/test_count_data.csv", row.names = 1)
#### make character ID bin
testing$Identity_bin_char <- recode(testing$Identity_bin, `0` = "Male", `1` = "Female")
testing$Identity_bin_char <- factor(testing$Identity_bin_char, levels = c("Male", "Female"))
#### make ID bin a factor
testing$Identity_bin <- as.factor(testing$Identity_bin)
#### make cell type column
testing$CellType <- testing_obj@meta.data$CellType


# Baseline Classifiers ####
## chr Y
y.count <- function(srat.object){
  # load gene expression count data
  srat.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA"))))
  
  # load gene annotations
  Rn7.gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
  Rn7.gtf <- as.data.frame(Rn7.gtf)
  
  # select Y chromosome genes
  y.genes <- Rn7.gtf %>% #from Rn7 gene annotations
    filter(seqnames == "Y") %>% #filter for chrY only
    select(gene_id, gene_name) %>% #select gene ids and names
    mutate(gene_name = coalesce(gene_name, gene_id)) %>% #replace NA name values with gene ID
    pull(gene_name) %>% #pull gene name values
    unique() #only unique values, returns 27 genes
  
  # create cumulative expresion of Y genes
  y.counts <- srat.counts %>%
    select(any_of(y.genes)) %>%
    rowSums()
  
  return(y.counts)
}
## Xist
Xist.count <- function(srat.object){
  # load gene expression count data
  Xist.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA")))) %>%
    pull("Xist")
  
  return(Xist.counts)
}

# Predictions ####
# class probabilities
## logistic regression
lr_prediction <- predict(lr_model,testing[,1:(ncol(testing)-3)], type = "response")
## support vector machine
svm_prediction <- predict(svm_model,testing[,1:(ncol(testing)-3)], type = "prob")
## random forest
rf_prediction <- predict(rf_model,testing[,1:(ncol(testing)-3)], type = "prob")
## multi-layer perceptron
mlp_prediction <- predict(mlp_model,testing[,1:(ncol(testing)-3)], type = "prob")
## chrY expression based prediction
chrY_prediction <- y.count(testing_obj)
## Xist expression based prediction
Xist_prediction <- Xist.count(testing_obj)

# binary classification
## logistic regression
lr_class <- ifelse(lr_prediction >0.5, 1, 0)
lr_class <- as.factor(lr_class)
## support vector machine
svm_prediction$class <- ifelse(svm_prediction$Female >0.5, "Female", "Male")
svm_prediction$class <- factor(svm_prediction$class, levels = c("Male", "Female"))
## random forest
rf_prediction$class <- ifelse(rf_prediction$Female >0.5, "Female", "Male")
rf_prediction$class <- factor(rf_prediction$class, levels = c("Male", "Female"))
## multi-layer perceptron
mlp_prediction$class <- ifelse(mlp_prediction$Female >0.5, "Female", "Male")
mlp_prediction$class <- factor(mlp_prediction$class, levels = c("Male", "Female"))
## chrY expression based prediction
chrY_class <- ifelse(chrY_prediction > 0.5, "Male", "Female")
chrY_class <- factor(chrY_class, levels = c("Male", "Female"))
## Xist expression based prediction
Xist_class <- ifelse(Xist_prediction < 0.5, "Male", "Female")
Xist_class <- factor(Xist_class, levels = c("Male", "Female"))

# Create data frame for evaluation ####
eval.df <- data.frame(CellType = testing$CellType,
                      Identity_bin = testing$Identity_bin,
                      Identity_bin_char  = testing$Identity_bin_char,
                      chrY_prediction = chrY_class,
                      Xist_prediction = Xist_class,
                      lr_prediction = lr_class,
                      svm_prediction = svm_prediction$class,
                      rf_prediction = rf_prediction$class,
                      mlp_prediction = mlp_prediction$class)
eval.df <- eval.df %>% mutate(Neuronal_Glial = case_when(CellType %in% c("Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3", "DA-Neuron") ~ "Neuronal",
                                                         CellType %in% c("Olig-1", "Olig-2", "Olig-3", "Astrocyte", "Polydendrocyte", "Microglia", "OPC-Olig-1", "Mural", "Endothelial") ~ "Glial"))
eval.df.split.neuronal.glial <- split(eval.df, f = eval.df$Neuronal_Glial)

# Accuracy ####
## Neuronal and Glial cells separately
neuronal.glial.acc <- lapply(eval.df.split.neuronal.glial %>% names(), function(celltype){
  chrY_confusion <- confusionMatrix(eval.df.split.neuronal.glial[[celltype]][["chrY_prediction"]], eval.df.split.neuronal.glial[[celltype]][["Identity_bin_char"]])
  Xist_confusion <- confusionMatrix(eval.df.split.neuronal.glial[[celltype]][["Xist_prediction"]], eval.df.split.neuronal.glial[[celltype]][["Identity_bin_char"]])
  lr_confusion <- confusionMatrix(eval.df.split.neuronal.glial[[celltype]][["lr_prediction"]], eval.df.split.neuronal.glial[[celltype]][["Identity_bin"]])
  svm_confusion <- confusionMatrix(eval.df.split.neuronal.glial[[celltype]][["svm_prediction"]], eval.df.split.neuronal.glial[[celltype]][["Identity_bin_char"]])
  rf_confusion <- confusionMatrix(eval.df.split.neuronal.glial[[celltype]][["rf_prediction"]], eval.df.split.neuronal.glial[[celltype]][["Identity_bin_char"]])
  mlp_confusion <- confusionMatrix(eval.df.split.neuronal.glial[[celltype]][["mlp_prediction"]], eval.df.split.neuronal.glial[[celltype]][["Identity_bin_char"]])
  
  
  ## accuracy table
  acc.table <- data.frame(Accuracy = c(chrY_confusion[["overall"]][["Accuracy"]],
                                       Xist_confusion[["overall"]][["Accuracy"]],
                                       lr_confusion[["overall"]][["Accuracy"]],
                                       svm_confusion[["overall"]][["Accuracy"]],
                                       rf_confusion[["overall"]][["Accuracy"]],
                                       mlp_confusion[["overall"]][["Accuracy"]]))
  rownames(acc.table) <- c("Chr Y", "Xist","Logistic Regression", "SVM", "Random Forest", "MLP")
  
  
  ## stacked bar plot of prediction accuracies
  ### make list of confusion matrices
  confusion.list <- list(ChrY = chrY_confusion,
                         Xist = Xist_confusion,
                         `Logistic Regression` = lr_confusion,
                         SVM = svm_confusion,
                         `Random Forest` = rf_confusion,
                         MLP = mlp_confusion)
  
  ### extract values to data frame with values for reference_prediction
  confusion.df <- data.frame(model = c("Chr Y","Xist", "Logistic Regression", "SVM", "Random Forest", "MLP"),
                             Male_correct = lapply(confusion.list, function(x){x[["table"]][1,1]}) %>% unlist(),
                             Female_incorrect = lapply(confusion.list, function(x){x[["table"]][1,2]}) %>% unlist(),
                             Male_incorrect = lapply(confusion.list, function(x){x[["table"]][2,1]}) %>% unlist(),
                             Female_correct = lapply(confusion.list, function(x){x[["table"]][2,2]}) %>% unlist())
  
  ### convert to long format and split reference level and prediction
  confusion.df.long <- confusion.df %>%
    pivot_longer(cols = Male_correct:Female_correct,
                 names_to = "prediction",
                 values_to = "count") %>%
    separate(col = prediction,
             into = c("reference","prediction"),
             sep = "_")
  
  ### convert variables to factors
  confusion.df.long <- confusion.df.long %>% mutate(reference = factor(reference, levels = c("Male", "Female")),
                                                    prediction = factor(prediction, levels = c("incorrect","correct")),
                                                    model = factor(model, levels = rev(c("Chr Y","Xist", "Logistic Regression", "SVM", "Random Forest", "MLP"))))
  
  ### create stacked bar plot of predictions split by sex
  confusion.plot <- ggplot(data = confusion.df.long, mapping = aes(x=model, y=count, fill=prediction)) + 
    geom_bar(position="fill", stat="identity") +
    facet_wrap( ~ reference) +
    theme_bw() +
    coord_flip() +
    labs(title = paste0("Confuson plot: ", celltype), x = "Model", y = "Proportion") +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
  
  ### save
  ggsave(plot = confusion.plot,
         file = paste0("plots/10_evaluation_celltype_specific/confusionplot.", celltype,".pdf"),
         height = 7,
         width = 10,
         device = "pdf")
  
  # return table
  return(acc.table)
})

names(neuronal.glial.acc) <- names(eval.df.split.neuronal.glial)
# merge to dataframe 
neuronal.glial.acc.df <- bind_cols(neuronal.glial.acc)
colnames(neuronal.glial.acc.df) <- names(eval.df.split.neuronal.glial)
## write out
write.csv(neuronal.glial.acc.df, file = "processed_data/10_evaluation_celltype_specific/Accuracy_neuronal_glial_table.csv")

# ROC + AUC ####
roc.eval.df <- data.frame(CellType = testing$CellType,
                          Identity_bin = testing$Identity_bin,
                          Identity_bin_char  = testing$Identity_bin_char,
                          chrY_prediction = chrY_prediction,
                          Xist_prediction = Xist_prediction,
                          lr_prediction = lr_prediction,
                          svm_prediction = svm_prediction[,2],
                          rf_prediction = rf_prediction[,2],
                          mlp_prediction = mlp_prediction[,2])
roc.eval.df <- roc.eval.df %>% mutate(Neuronal_Glial = case_when(CellType %in% c("Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3", "DA-Neuron") ~ "Neuronal",
                                                                 CellType %in% c("Olig-1", "Olig-2", "Olig-3", "Astrocyte", "Polydendrocyte", "Microglia", "OPC-Olig-1", "Mural", "Endothelial") ~ "Glial"))
roc.eval.df.split.neuronal.glial <- split(roc.eval.df, f = roc.eval.df$Neuronal_Glial) # table split by neuronal and glial cell types

## Neuronal and glial cell types separately
neuronal.glial.auc <- lapply(roc.eval.df.split.neuronal.glial %>% names(), function(celltype){
  ## calculate ROC
  Xist_roc <- roc(roc.eval.df.split.neuronal.glial[[celltype]][["Identity_bin_char"]],roc.eval.df.split.neuronal.glial[[celltype]][["Xist_prediction"]], levels = c("Female", "Male"), direction = ">")
  chrY_roc <- roc(roc.eval.df.split.neuronal.glial[[celltype]][["Identity_bin_char"]],roc.eval.df.split.neuronal.glial[[celltype]][["chrY_prediction"]], levels = c("Female", "Male"))
  lr_roc <- roc(roc.eval.df.split.neuronal.glial[[celltype]][["Identity_bin"]],roc.eval.df.split.neuronal.glial[[celltype]][["lr_prediction"]], levels = c(1,0))
  svm_roc <- roc(roc.eval.df.split.neuronal.glial[[celltype]][["Identity_bin_char"]],roc.eval.df.split.neuronal.glial[[celltype]][["svm_prediction"]], levels = c("Female", "Male"))
  rf_roc <- roc(roc.eval.df.split.neuronal.glial[[celltype]][["Identity_bin_char"]],roc.eval.df.split.neuronal.glial[[celltype]][["rf_prediction"]], levels = c("Female", "Male"))
  mlp_roc <- roc(roc.eval.df.split.neuronal.glial[[celltype]][["Identity_bin_char"]],roc.eval.df.split.neuronal.glial[[celltype]][["mlp_prediction"]], levels = c("Female", "Male"))
  
  ## ROC curve
  g <- ggroc(data = list(`Chr Y` = chrY_roc,
                         `Xist` = Xist_roc,
                         `Logistic Regression` = lr_roc,
                         `SVM` = svm_roc,
                         `Random Forest` = rf_roc,
                         `MLP` = mlp_roc)) +
    geom_abline(slope = 1, intercept = 1, linetype = "dashed") +
    labs(color = "Model", title = celltype) +
    theme_bw()
  
  ggsave(filename = paste0("plots/10_evaluation_celltype_specific/ROC_", celltype,"_curves.pdf"),
         plot = g + theme(text = element_text(size = 20)),
         height = 10,
         width = 12,
         device = "pdf")
  
  ## AUC table
  auc.table <- data.frame(AUC = c(chrY_roc[["auc"]] %>% as.numeric(),
                                  Xist_roc[["auc"]] %>% as.numeric(),
                                  lr_roc[["auc"]] %>% as.numeric(),
                                  svm_roc[["auc"]] %>% as.numeric(),
                                  rf_roc[["auc"]] %>% as.numeric(),
                                  mlp_roc[["auc"]] %>% as.numeric()))
  rownames(auc.table) <- c("Chr Y", "Xist", "Logistic Regression","SVM", "Random Forest", "MLP")
  return(auc.table)
})
names(neuronal.glial.auc) <- names(roc.eval.df.split.neuronal.glial)
### merge to dataframe 
neuronal.glial.auc.df <- bind_cols(neuronal.glial.auc)
colnames(neuronal.glial.auc.df) <- names(roc.eval.df.split.neuronal.glial)
# Write out results
write.csv(neuronal.glial.auc.df, file = "processed_data/10_evaluation_celltype_specific/AUCs_neuronal_glial_table.csv")

# sesionInfo ####
sessionInfo()
```

```{bash filename="10_evaluation_celltype_specific.sh"}
#!/bin/bash
#
#SBATCH --job-name=10_evaluation_celltype_specific
#SBATCH --output=logs/10_evaluation_celltype_specific.out
#SBATCH --error=logs/10_evaluation_celltype_specific.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@mail.edu

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/10_evaluation_celltype_specific.R
```

### Mutual Information
To compare the information shared between a gene's expression and cell sex between neuronal and non-neuronal cell types, the mutual information of the two variables was calculated for the two broad cell types separately. Mutual information of transcript count data and cell sex, for all selected model genes, was calculated using the `mmi.pw()` function from the `mpmi` package in R (version 0.43.2.1). For calculation of gene's expression and cell sex mutual information content in neuronal or non-neuronal populations, the VTA training partition was separated into neuronal (Glut-Neuron-1, Glut-Neuron-2, Glut-Neuron-3, GABA-Neuron-1, GABA-Neuron-2, GABA-Neuron-3, DA-Neuron) and non-neuronal (Olig-1, Olig-2, Olig-3, Astrocyte, Polydendrocyte, Microglia, OPC-Olig-1, Mural, Endothelial) populations.

```{r filename="11_mutual_information.R"}
# Setup ####
# libraries
library(Seurat)
library(dplyr)
library(ggplot2)
library(tidyr)
library(infotheo)
library(mpmi)
library(forcats)

# set seed
set.seed(1234)

# data
## training object
Rn7_VTA.training <- readRDS("processed_data/2_create_splits/Rn7_VTA_training.RDS")
Rn7_VTA.training@meta.data <- Rn7_VTA.training@meta.data %>%
  mutate(Neuronal = case_when(CellType %in% c("Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3", "DA-Neuron") ~ "Neuronal",
                              CellType %in% c("Olig-1", "Olig-2", "Olig-3", "Astrocyte", "Polydendrocyte", "Microglia", "OPC-Olig-1", "Mural", "Endothelial") ~ "Non-neuronal"))

## genes
selected.genes <- read.csv("processed_data/4_feature_selection_Boruta/Boruta_final_decisions.csv") %>% 
  filter(finalDecision == "Confirmed") %>% 
  pull("variable")

# mpmpi calculation ####
# extract count matrix
count.data <- as.data.frame(t(as.matrix(GetAssayData(object = Rn7_VTA.training,slot = "data",assay = "RNA")))) %>% 
  select(all_of(selected.genes))
# create cell lists for neuronal and non-neuronal cells
neuronal.cells <- Rn7_VTA.training@meta.data %>% filter(Neuronal == "Neuronal") %>% rownames()
nonneuronal.cells <- Rn7_VTA.training@meta.data %>% filter(Neuronal != "Neuronal") %>% rownames()

# create count dfs for neuronal and non-neuronal cells
count.data.neurons <- count.data[neuronal.cells,] 
count.data.nonneurons <- count.data[nonneuronal.cells,] 

# calculate mutual info
minfo <- lapply(selected.genes, function(gene){
  # calculate for neuronal cells
  neuronal.info <- mmi.pw(count.data.neurons %>% select(gene),
                          Rn7_VTA.training@meta.data[neuronal.cells,] %>% select(Sex))$mi 
  # calculate for non-neuronal cells
  nonneuronal.info <- mmi.pw(count.data.nonneurons %>% select(gene),
                             Rn7_VTA.training@meta.data[nonneuronal.cells,] %>% select(Sex))$mi
  # return vector of gene, minfo for neuronal, and minfo for non-neuronal
  return(c(gene, neuronal.info, nonneuronal.info))
})

# merge to dataframe
minfo.training.df <- as.data.frame(do.call(rbind,minfo))
# modify dataframe
colnames(minfo.training.df) <- c("Gene","neuronal", "nonneuronal") #set column names to be informative
minfo.global.df <- minfo.training.df %>%
  mutate(neuronal = neuronal %>% as.numeric(),
         nonneuronal = nonneuronal %>% as.numeric())
# pivot longer
minfo.training.df.long <- minfo.training.df %>% 
  pivot_longer(cols = neuronal:nonneuronal,
               names_to = "cell.type",
               values_to = "mutual.info") %>% 
  mutate(cell.type = recode(cell.type, neuronal = "Neuronal", nonneuronal = "Non-neuronal")) %>% 
  mutate(cell.type = factor(cell.type, levels = c("Neuronal", "Non-neuronal")),
         mutual.info = mutual.info %>% as.numeric())

# write out
write.csv(minfo.training.df.long, "processed_data/11_mutual_information/mutualinfo.training.df.csv")

# Plot mutual info distribution ####
# density
training.dens <- ggplot(data = minfo.training.df.long, aes(x = mutual.info, fill = cell.type)) +
  scale_fill_manual(values = c(Neuronal = "#624185", `Non-neuronal` = "#FFA345")) +
  geom_density(alpha = 0.7) +
  scale_x_continuous(trans = "log10") +
  labs(x = "Mutual Information", y = "Density", fill = "Cell Type") +
  theme_bw() +
  theme(text = element_text(size = 15), legend.position = c(0.2,0.9))

# save
ggsave(plot = training.dens,
       file = "plots/11_mutual_information/training.dens.pdf",
       device = "pdf",
       height = 10,
       width = 10)

# cell type comparison ####
training.minfo.df.wide <- minfo.training.df.long %>% 
  pivot_wider(names_from = "cell.type",
              values_from = "mutual.info") %>% mutate(difference = Neuronal - `Non-neuronal`)

training.diff <- ggplot(training.minfo.df.wide, aes(x = fct_reorder(Gene, difference), y = difference)) +
  geom_point(shape = 1) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Genes", y = "Mutual information (Neuronal - Non-neuronal)") +
  theme_bw() +
  theme(axis.text.x=element_blank(),
        panel.grid = element_blank())

# save
ggsave(plot = training.diff,
       file = "plots/11_mutual_information/training.diff.rank.pdf",
       device = "pdf",
       height = 10,
       width = 10)
write.csv(training.minfo.df.wide, file = "processed_data/11_mutual_information/training.minfo.wide.csv")


# Gene distributions ####
# sum number of expressed model genes in each cell type
nfeature.neurons <- data.frame(cell = row.names(count.data.neurons),
                                        cell.type = rep("Neuronal", nrow(count.data.neurons)),
                                        nFeature = rowSums(count.data.neurons != 0))
nfeature.nonneurons <- data.frame(cell = row.names(count.data.nonneurons),
                                           cell.type = rep("Non-neuronal", nrow(count.data.nonneurons)),
                                           nFeature = rowSums(count.data.nonneurons != 0))
nfeature <- rbind(nfeature.neurons,nfeature.nonneurons)


gene.distb <- ggplot(nfeature, aes(x = nFeature, fill = cell.type)) +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c("Neuronal" = "#624185", "Non-neuronal" = "#ffa345")) +
  labs(x = "Number of genes", y = "Density") +
  theme_bw() +
  theme(panel.grid = element_blank(),
        legend.position = c(0.1,0.9),
        legend.title= element_blank(),
        text = element_text(size = 15))

# save output
ggsave(plot = gene.distb,
       filename = "plots/11_mutual_information/training.model.nFeature.distb.pdf",
       height = 10,
       width = 10)

# sessionInfo ####
sessionInfo()
```

```{bash filename="11_mutual_information.sh"}
#!/bin/bash
#
#SBATCH --job-name=11_mutual_information
#SBATCH --output=logs/11_mutual_information.out
#SBATCH --error=logs/11_mutual_information.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@mail.edu

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/11_mutual_information.R
```


### Cell Type-Specific Models
Given the observed disparity in performance of models in neuronal and non-neuronal cell populations, we sought to determine if cell type-specific models would improve performance over pan-cellular models. Before fitting cell type-specific models, the VTA training data partition was split into subsets for either neuronal (Glut-Neuron-1, Glut-Neuron-2, Glut-Neuron-3, GABA-Neuron-1, GABA-Neuron-2, GABA-Neuron-3, DA-Neuron)  or non-neuronal (Olig-1, Olig-2, Olig-3, Astrocyte, Polydendrocyte, Microglia, OPC-Olig-1, Mural, Endothelial) cell type groups. Feature selection with Boruta was repeated with significant DEGs within each cell type subset. LR, RF, SVM, and MLP models were fit as described above for neuronal and non-neuronal cell type subsets.

#### Create Cell Type-Specific Partitions
To train and evaluate cell type-specific models, we first defined our cell type-specific training and testing data partitions. The same training/testing partitions as pan-cellular models were used, however each was further partitioned to neuronal and non-neuronal sets. Because sex-dependent DEGs analyses was initially conducted within each cell type, it was unessecary to repeat this stage of feature selection. However, the results of DEG analysis did need to be partitioned based on their results within either partition.

```{r filename="12_create_splits_celltype_specific.R"}
# Setup ####
# libraries
library(Seurat)
library(dplyr)
# library(tibble)
# library(tidyr)

# seed
set.seed(1234)

# data
## training
Rn7_VTA.training <- readRDS("processed_data/2_create_splits/Rn7_VTA_training.RDS")
## testing
Rn7_VTA.testing <- readRDS("processed_data/2_create_splits/Rn7_VTA_testing.RDS")
## previous DEG results
Sex_DEGs <- read.csv("processed_data/3_feature_selection_DEGs/DEGs_sex_cluster_VTA_sig.csv")

# add Neruonal/Non-neuronal metadata ####
## make neuronal and non-neuronal cell labels
Rn7_VTA.training@meta.data <- Rn7_VTA.training@meta.data %>%
  mutate(Neuronal = case_when(CellType %in% c("Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3", "DA-Neuron") ~ "Neuronal",
                              CellType %in% c("Olig-1", "Olig-2", "Olig-3", "Astrocyte", "Polydendrocyte", "Microglia", "OPC-Olig-1", "Mural", "Endothelial") ~ "Non-neuronal")) # make a new column to designate neuronal and non-neuronal
Rn7_VTA.training@meta.data <- Rn7_VTA.training@meta.data %>% 
  mutate(Neuronal = factor(Neuronal, levels = c("Neuronal", "Non-neuronal"))) # make cell type and neuronal/non-neuronal factors 

Rn7_VTA.testing@meta.data <- Rn7_VTA.testing@meta.data %>%
  mutate(Neuronal = case_when(CellType %in% c("Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3", "DA-Neuron") ~ "Neuronal",
                              CellType %in% c("Olig-1", "Olig-2", "Olig-3", "Astrocyte", "Polydendrocyte", "Microglia", "OPC-Olig-1", "Mural", "Endothelial") ~ "Non-neuronal")) # make a new column to designate neuronal and non-neuronal
Rn7_VTA.testing@meta.data <- Rn7_VTA.testing@meta.data %>% 
  mutate(Neuronal = factor(Neuronal, levels = c("Neuronal", "Non-neuronal"))) # make cell type and neuronal/non-neuronal factors 

# split DEG list by neuronal and non-neuronal cluster results ####
### neuronal
neuronal.degs <- Sex_DEGs %>%
  filter(Cluster %in% c("Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3", "DA-Neuron")) %>% 
  pull(GeneName) %>% 
  unique()
print(paste("Neuronal DEGs:", length(neuronal.degs)))

### non-neuronal
nonneuronal.degs <- Sex_DEGs %>% filter(Cluster %in% c("Olig-1", "Olig-2", "Olig-3", "Astrocyte", "Polydendrocyte", "Microglia", "OPC-Olig-1", "Mural", "Endothelial")) %>% 
  pull(GeneName) %>% 
  unique()
print(paste("Non-neuronal DEGs:", length(nonneuronal.degs)))


# make subsets for cell type ####
## training
Rn7_VTA.training@active.ident <- Rn7_VTA.training$Neuronal
Rn7_VTA.training.neuronal <- subset(x = Rn7_VTA.training, idents = "Neuronal")
Rn7_VTA.training.nonneuronal <- subset(x = Rn7_VTA.training, idents = "Non-neuronal")

## testing
Rn7_VTA.testing@active.ident <- Rn7_VTA.testing$Neuronal
Rn7_VTA.testing.neuronal <- subset(x = Rn7_VTA.testing, idents = "Neuronal")
Rn7_VTA.testing.nonneuronal <- subset(x = Rn7_VTA.testing, idents = "Non-neuronal")

# make subsets of count data ####
# training 
## neuronal
### First pull the count data
training.neuronal.count_data_Full <- as.data.frame(t(as.matrix(GetAssayData(object = Rn7_VTA.training.neuronal,slot = "data",assay = "RNA"))))
### check if rownames are in same order as the identities vector 
all(names(Idents(Rn7_VTA.training.neuronal)) == rownames(training.neuronal.count_data_Full)) 
### Now just create a new column in the training.neuronal.count_data_Full for identity
training.neuronal.count_data_Full$Identity <- as.factor(Rn7_VTA.training.neuronal$Sex)
### Convert identitity to binary code. 
training.neuronal.count_data_Full$Identity_bin <- ifelse(training.neuronal.count_data_Full$Identity  == "Female",
                                                         1, #Females are 1
                                                         0) #Males are 0
### Create a subset of count data full containing all DEGs from neuronal celltypes
training.neuronal.count_data_subset <- training.neuronal.count_data_Full[,c(neuronal.degs,"Identity_bin")]


## non-neuronal
### First pull the count data
training.nonneuronal.count_data_Full <- as.data.frame(t(as.matrix(GetAssayData(object = Rn7_VTA.training.nonneuronal,slot = "data",assay = "RNA"))))
### check if rownames are in same order as the identities vector 
all(names(Idents(Rn7_VTA.training.nonneuronal)) == rownames(training.nonneuronal.count_data_Full))
### Now just create a new column in the training.nonneuronal.count_data_Full for identity
training.nonneuronal.count_data_Full$Identity <- as.factor(Rn7_VTA.training.nonneuronal$Sex)
### Convert identitity to binary code. 
training.nonneuronal.count_data_Full$Identity_bin <- ifelse(training.nonneuronal.count_data_Full$Identity  == "Female",
                                                            1, #Females are 1
                                                            0) #Males are 0
### Create a subset of count data full containing all DEGs from non-neuronal celltypes
training.nonneuronal.count_data_subset <- training.nonneuronal.count_data_Full[,c(nonneuronal.degs,"Identity_bin")]


# save outputs ####
## seurat objects
saveRDS(Rn7_VTA.training.neuronal, "processed_data/12_create_splits_celltype_specific/Rn7_VTA_training_neuronal.RDS")
saveRDS(Rn7_VTA.training.nonneuronal, "processed_data/12_create_splits_celltype_specific/Rn7_VTA_training_nonneuronal.RDS")

saveRDS(Rn7_VTA.testing.neuronal, "processed_data/12_create_splits_celltype_specific/Rn7_VTA_testing_neuronal.RDS")
saveRDS(Rn7_VTA.testing.nonneuronal, "processed_data/12_create_splits_celltype_specific/Rn7_VTA_testing_nonneuronal.RDS")

## count data subsets
saveRDS(training.neuronal.count_data_subset, "processed_data/12_create_splits_celltype_specific/training_neuronal_count_subset.RDS")
saveRDS(training.nonneuronal.count_data_subset, "processed_data/12_create_splits_celltype_specific/training_nonneuronal_count_subset.RDS")

# sessionInfo ####
sessionInfo()
```

```{bash filename="12_create_splits_celltype_specific.sh"}
#!/bin/bash
#
#SBATCH --job-name=12_create_splits_celltype_specific
#SBATCH --output=logs/12_create_splits_celltype_specific.out
#SBATCH --error=logs/12_create_splits_celltype_specific.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/12_create_splits_celltype_specific.R
```


#### Feature Selection
Boruta feature selection was conducted for each set of significant neuronal or non-neuronal DEGs, using the same parameters as in pan-cellular feature selection. Following feature selection, model training and testing data was prepared for each neuronal and non-neuronal partition using the same workflow as with pan-cellular models.

##### Neuronal
```{r filename="4_feature_selection_Boruta_neuronal.R"}
# Setup ####
## libraries ####
library(Seurat)
library(Boruta)
library(dplyr)

## set seed ####
set.seed(1234)

## data ####
# training counts
training <- readRDS("processed_data/12_create_splits_celltype_specific/training_neuronal_count_subset.RDS")
# testing counts
testing <- readRDS("processed_data/12_create_splits_celltype_specific/Rn7_VTA_testing_neuronal.RDS")

# Feature Selection ####
VTA_Boruta <- Boruta(Identity_bin ~ ., data = training, maxRuns = 3000, doTrace = 2)
# Save output
saveRDS(VTA_Boruta,"processed_data/neuronal/4_feature_selection_Boruta/VTA_Boruta_max3000.RDS")

# Post Selection Processing ####
# print summary
VTA_Boruta

# perform rough fix 
VTA_Boruta <- TentativeRoughFix(VTA_Boruta)
VTA_Boruta

# extract decisions for features
VTA_Boruta_decision <- VTA_Boruta$finalDecision %>% data.frame()
colnames(VTA_Boruta_decision) <- c("finalDecision")
VTA_Boruta_decision$variable <- rownames(VTA_Boruta_decision)
VTA_Boruta_decision <- VTA_Boruta_decision %>% select(variable, finalDecision) # reorder for my sanity

# Get column names with confirmed values
confirmed_columns <- VTA_Boruta_decision$variable[VTA_Boruta_decision$finalDecision == "Confirmed"]

# Create count data subsets ####
## Create training count data subsets
training_important <- training[, colnames(training) %in% confirmed_columns]
### Add identity bin back in
training_important$Identity_bin <- training$Identity_bin

## Create testing count data subset
count_data <- as.data.frame(t(as.matrix(GetAssayData(object = testing,slot = "data",assay = "RNA"))))
### check if rownames are in same order as the identities vector 
all(names(Idents(testing)) == rownames(count_data)) #TRUE 
### Now just create a new column in the count_data_full for identity
count_data$Identity <- as.factor(testing$Sex)
### Convert identitity to binary code. 
count_data$Identity_bin <- ifelse(count_data$Identity  == "Female",
                                  1, #Females are 1
                                  0) #Males are 0
### Create a subset of count data containing the same features as the training set
test_important <- count_data[,colnames(count_data) %in% colnames(training_important)]

# Save outputs ####
## Boruta variable final decisions
write.csv(VTA_Boruta_decision, file = "processed_data/neuronal/4_feature_selection_Boruta/Boruta_final_decisions.csv", row.names = F)
## training and testing count data frames
write.csv(training_important, file = "processed_data/neuronal/4_feature_selection_Boruta/training_count_data.csv")
write.csv(test_important, file = "processed_data/neuronal/4_feature_selection_Boruta/test_count_data.csv")

# sessionInfo ####
sessionInfo()

# Session Info ####
sessionInfo()
```

```{bash filename="4_feature_selection_Boruta_neuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=4_feature_selection_Boruta_neuronal
#SBATCH --output=logs/neuronal/4_feature_selection_Boruta_neuronal.out
#SBATCH --error=logs/neuronal/4_feature_selection_Boruta_neuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=long
#SBATCH --time=150:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/neuronal/4_feature_selection_Boruta_neuronal.R
```

##### Non-neuronal
```{r filename="4_feature_selection_Boruta_nonneuronal.R"}
# Setup ####
## libraries ####
library(Seurat)
library(Boruta)
library(dplyr)

## set seed ####
set.seed(1234)

## data ####
# training counts
training <- readRDS("processed_data/12_create_splits_celltype_specific/training_nonneuronal_count_subset.RDS")
# testing counts
testing <- readRDS("processed_data/12_create_splits_celltype_specific/Rn7_VTA_testing_nonneuronal.RDS")

# Feature Selection ####
VTA_Boruta <- Boruta(Identity_bin ~ ., data = training, maxRuns = 3000, doTrace = 2)
# Save output
saveRDS(VTA_Boruta,"processed_data/non_neuronal/4_feature_selection_Boruta/VTA_Boruta_max3000.RDS")

# Post Selection Processing ####
# print summary
VTA_Boruta

# perform rough fix 
VTA_Boruta <- TentativeRoughFix(VTA_Boruta)
VTA_Boruta

# extract decisions for features
VTA_Boruta_decision <- VTA_Boruta$finalDecision %>% data.frame()
colnames(VTA_Boruta_decision) <- c("finalDecision")
VTA_Boruta_decision$variable <- rownames(VTA_Boruta_decision)
VTA_Boruta_decision <- VTA_Boruta_decision %>% select(variable, finalDecision) # reorder for my sanity

# Get column names with confirmed values
confirmed_columns <- VTA_Boruta_decision$variable[VTA_Boruta_decision$finalDecision == "Confirmed"]

# Create count data subsets ####
## Create training count data subsets
training_important <- training[, colnames(training) %in% confirmed_columns]
### Add identity bin back in
training_important$Identity_bin <- training$Identity_bin

## Create testing count data subset
count_data <- as.data.frame(t(as.matrix(GetAssayData(object = testing,slot = "data",assay = "RNA"))))
### check if rownames are in same order as the identities vector 
all(names(Idents(testing)) == rownames(count_data)) #TRUE 
### Now just create a new column in the count_data_full for identity
count_data$Identity <- as.factor(testing$Sex)
### Convert identitity to binary code. 
count_data$Identity_bin <- ifelse(count_data$Identity  == "Female",
                                  1, #Females are 1
                                  0) #Males are 0
### Create a subset of count data containing the same features as the training set
test_important <- count_data[,colnames(count_data) %in% colnames(training_important)]

# Save outputs ####
## Boruta variable final decisions
write.csv(VTA_Boruta_decision, file = "processed_data/non_neuronal/4_feature_selection_Boruta/Boruta_final_decisions.csv", row.names = F)
## training and testing count data frames
write.csv(training_important, file = "processed_data/non_neuronal/4_feature_selection_Boruta/training_count_data.csv")
write.csv(test_important, file = "processed_data/non_neuronal/4_feature_selection_Boruta/test_count_data.csv")

# sessionInfo ####
sessionInfo()

# Session Info ####
sessionInfo()
```

```{bash filename="4_feature_selection_Boruta_nonneuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=4_feature_selection_Boruta_nonneuronal
#SBATCH --output=logs/non_neuronal/4_feature_selection_Boruta_nonneuronal.out
#SBATCH --error=logs/non_neuronal/4_feature_selection_Boruta_nonneuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=long
#SBATCH --time=150:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/non_neuronal/4_feature_selection_Boruta_nonneuronal.R
```


#### Model Training
Cell type-specific sex classification models were fit for neuronal and non-neuronal cell partitions using the same parameters as described in pan-cellular model training.

##### Neuronal
###### Logistic Regression
```{r filename="5_training_logistic_regression_neuronal.R"}
# Set up ####
## libraries
library(caret)
library(tidyverse)

## set seed
set.seed(1234)

## load data
### training dataframe
training <- read.csv("processed_data/neuronal/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- as.factor(training$Identity_bin)

# Train Model ####
lr_model <- glm(Identity_bin ~ .,
                data = training,
                family = "binomial")
# Summary
summary(lr_model)

# Write out files ####
saveRDS(lr_model, file = "processed_data/neuronal/5_training_logistic_regression/lr_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="5_training_logistic_regression_neuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=5_training_logistic_regression_neuronal
#SBATCH --output=logs/neuronal/5_training_logistic_regression_neuronal.out
#SBATCH --error=logs/neuronal/5_training_logistic_regression_neuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/neuronal/5_training_logistic_regression_neuronal.R
```

###### Random Forest
```{r filename="6_training_random_forest_neuronal.R"}
# Setup ####
library(randomForest)
library(ROCR)
library(caret)
library(tidyverse)
library(doParallel)

## set seed
set.seed(1234)
## setup parallel
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

## load data
### training dataframe
training <- read.csv("processed_data/neuronal/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- recode(training$Identity_bin, `0` = "Male", `1` = "Female")
training$Identity_bin <- factor(training$Identity_bin, levels = c("Male", "Female"))

# Train Model ####
mtry_values <- seq(from = 2, to = 334, by = 12)

# Generate all combinations
tune.grid <- expand.grid(mtry = mtry_values)

train.ctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           classProbs = T,
                           allowParallel = T)
rf_model <- train(Identity_bin ~ ., data = training, 
                  method = "rf",
                  trControl = train.ctrl,
                  tuneGrid = tune.grid,
                  ntree = 1000)
rf_model

stopCluster(cl)

# Write out files ####
saveRDS(rf_model, file = "processed_data/neuronal/6_training_random_forest/rf_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="6_training_random_forest_neuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=6_training_random_forest_neuronal
#SBATCH --output=logs/neuronal/6_training_random_forest_neuronal.out
#SBATCH --error=logs/neuronal/6_training_random_forest_neuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=medium
#SBATCH --time=50:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/neuronal/6_training_random_forest_neuronal.R
```

###### Support Vector Machine
```{r filename="7_training_svm_neuronal.R"}
# Setup ####
library(kernlab)
library(ROCR)
library(caret)
library(tidyverse)
library(doParallel)

## set seed
set.seed(1234)
## setup parallel
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

## load data
### training data frame
training <- read.csv("processed_data/neuronal/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- recode(training$Identity_bin, `0` = "Male", `1` = "Female")
training$Identity_bin <- factor(training$Identity_bin, levels = c("Male", "Female"))

# Train Model ####
## Create vectors for sigma and C
sigma_values <- c(0.0001,0.001,0.01,0.1)
C_values <- c(c(0.1,0.2,0.5,1,1.5,2,5,10))

## Generate training grid
train.grid <- expand.grid(sigma = sigma_values, C = C_values)

## create training control parameters
train.ctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           classProbs = T,
                           allowParallel = T)

svm_model <- train(Identity_bin ~ ., data = training, 
                   method = "svmRadial",
                   verbose = T,
                   trControl = train.ctrl,
                   tuneGrid = train.grid)

svm_model

stopCluster(cl)
# Write out files ####
saveRDS(svm_model, file = "processed_data/neuronal/7_training_svm/svm_rad_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="7_training_svm_neuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=7_training_svm_neuronal
#SBATCH --output=logs/neuronal/7_training_svm_neuronal.out
#SBATCH --error=logs/neuronal/7_training_svm_neuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=long
#SBATCH --time=72:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/neuronal/7_training_svm_neuronal.R
```

###### Multi-layer Perceptron
```{r filename="8_training_mlp_neuronal.R"}
# Set up ####
## libraries
library(RSNNS)
library(ROCR)
library(caret)
library(tidyverse)
library(doParallel)

## set seed
set.seed(1234)
## setup parallel
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

## load data
### training dataframe
training <- read.csv("processed_data/neuronal/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- recode(training$Identity_bin, `0` = "Male", `1` = "Female")
training$Identity_bin <- factor(training$Identity_bin, levels = c("Male", "Female"))

# Train Model ####
# Create vectors for layer1, layer2, and decay
layer1_values <- c(1,seq(from = 5, to = 20, by = 5))
layer2_values <- c(0, round(layer1_values / 2)) %>% unique()
layer3_values <- round(layer2_values / 2)  
decay_values <- seq(from = 0, to = 0.2, by = 0.05)

# Generate all combinations
train.grid <- expand.grid(layer1 = layer1_values,
                          layer2 = layer2_values,
                          layer3 = layer3_values,
                          decay = decay_values)

# Filter rows where layer2 is smaller than layer1
train.grid <- train.grid[train.grid$layer2 < train.grid$layer1, ]

# Filter rows where layer3 is smaller than layer2
train.grid <- train.grid[train.grid$layer3 < train.grid$layer2, ]

train.ctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           classProbs = T,
                           allowParallel = T)
mlp_model <- caret::train(Identity_bin ~ ., data = training, 
                          method = "mlpWeightDecayML",
                          trControl = train.ctrl,
                          tuneGrid = train.grid)

mlp_model

stopCluster(cl)
# Write out files ####
saveRDS(mlp_model, file = "processed_data/neuronal/8_training_mlp/mlpwdml_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="8_training_mlp_neuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=8_training_mlp_neuronal
#SBATCH --output=logs/neuronal/8_training_mlp_neuronal.out
#SBATCH --error=logs/neuronal/8_training_mlp_neuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=medium
#SBATCH --time=50:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/neuronal/8_training_mlp_neuronal.R
```


##### Non-neuronal
###### Logistic Regression
```{r filename="5_training_logistic_regression_nonneuronal.R"}
# Set up ####
## libraries
library(caret)
library(tidyverse)

## set seed
set.seed(1234)

## load data
### training dataframe
training <- read.csv("processed_data/non_neuronal/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- as.factor(training$Identity_bin)

# Train Model ####
lr_model <- glm(Identity_bin ~ .,
                data = training,
                family = "binomial")
# Summary
summary(lr_model)

# Write out files ####
saveRDS(lr_model, file = "processed_data/non_neuronal/5_training_logistic_regression/lr_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="5_training_logistic_regression_nonneuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=5_training_logistic_regression_nonneuronal
#SBATCH --output=logs/non_neuronal/5_training_logistic_regression_nonneuronal.out
#SBATCH --error=logs/non_neuronal/5_training_logistic_regression_nonneuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/non_neuronal/5_training_logistic_regression_nonneuronal.R
```

###### Random Forest
```{r filename="6_training_random_forest_nonneuronal.R"}
# Setup ####
library(randomForest)
library(ROCR)
library(caret)
library(tidyverse)
library(doParallel)

## set seed
set.seed(1234)
## setup parallel
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

## load data
### training dataframe
training <- read.csv("processed_data/non_neuronal/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- recode(training$Identity_bin, `0` = "Male", `1` = "Female")
training$Identity_bin <- factor(training$Identity_bin, levels = c("Male", "Female"))

# Train Model ####
mtry_values <- seq(from = 2, to = 334, by = 12)

# Generate all combinations
tune.grid <- expand.grid(mtry = mtry_values)

train.ctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           classProbs = T,
                           allowParallel = T)
rf_model <- train(Identity_bin ~ ., data = training, 
                  method = "rf",
                  trControl = train.ctrl,
                  tuneGrid = tune.grid,
                  ntree = 1000)
rf_model

stopCluster(cl)

# Write out files ####
saveRDS(rf_model, file = "processed_data/non_neuronal/6_training_random_forest/rf_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="6_training_random_forest_nonneuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=6_training_random_forest_nonneuronal
#SBATCH --output=logs/non_neuronal/6_training_random_forest_nonneuronal.out
#SBATCH --error=logs/non_neuronal/6_training_random_forest_nonneuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=medium
#SBATCH --time=50:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/non_neuronal/6_training_random_forest_nonneuronal.R
```

###### Support Vector Machine
```{r filename="7_training_svm_nonneuronal.R"}
# Setup ####
library(kernlab)
library(ROCR)
library(caret)
library(tidyverse)
library(doParallel)

## set seed
set.seed(1234)
## setup parallel
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

## load data
### training data frame
training <- read.csv("processed_data/non_neuronal/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- recode(training$Identity_bin, `0` = "Male", `1` = "Female")
training$Identity_bin <- factor(training$Identity_bin, levels = c("Male", "Female"))

# Train Model ####
## Create vectors for sigma and C
sigma_values <- c(0.0001,0.001,0.01,0.1)
C_values <- c(c(0.1,0.2,0.5,1,1.5,2,5,10))

## Generate training grid
train.grid <- expand.grid(sigma = sigma_values, C = C_values)

## create training control parameters
train.ctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           classProbs = T,
                           allowParallel = T)

svm_model <- train(Identity_bin ~ ., data = training, 
                   method = "svmRadial",
                   verbose = T,
                   trControl = train.ctrl,
                   tuneGrid = train.grid)

svm_model

stopCluster(cl)
# Write out files ####
saveRDS(svm_model, file = "processed_data/non_neuronal/7_training_svm/svm_rad_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="7_training_svm_nonneuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=7_training_svm_nonneuronal
#SBATCH --output=logs/non_neuronal/7_training_svm_nonneuronal.out
#SBATCH --error=logs/non_neuronal/7_training_svm_nonneuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=long
#SBATCH --time=72:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/non_neuronal/7_training_svm_nonneuronal.R
```

###### Multi-layer Perceptron
```{r filename="8_training_mlp_nonneuronal.R"}
# Set up ####
## libraries
library(RSNNS)
library(ROCR)
library(caret)
library(tidyverse)
library(doParallel)

## set seed
set.seed(1234)
## setup parallel
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

## load data
### training dataframe
training <- read.csv("processed_data/non_neuronal/4_feature_selection_Boruta/training_count_data.csv", row.names = 1)
training$Identity_bin <- recode(training$Identity_bin, `0` = "Male", `1` = "Female")
training$Identity_bin <- factor(training$Identity_bin, levels = c("Male", "Female"))

# Train Model ####
# Create vectors for layer1, layer2, and decay
layer1_values <- c(1,seq(from = 5, to = 20, by = 5))
layer2_values <- c(0, round(layer1_values / 2)) %>% unique()
layer3_values <- round(layer2_values / 2)  
decay_values <- seq(from = 0, to = 0.2, by = 0.05)

# Generate all combinations
train.grid <- expand.grid(layer1 = layer1_values,
                          layer2 = layer2_values,
                          layer3 = layer3_values,
                          decay = decay_values)

# Filter rows where layer2 is smaller than layer1
train.grid <- train.grid[train.grid$layer2 < train.grid$layer1, ]

# Filter rows where layer3 is smaller than layer2
train.grid <- train.grid[train.grid$layer3 < train.grid$layer2, ]

train.ctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           classProbs = T,
                           allowParallel = T)
mlp_model <- caret::train(Identity_bin ~ ., data = training, 
                          method = "mlpWeightDecayML",
                          trControl = train.ctrl,
                          tuneGrid = train.grid)

mlp_model

stopCluster(cl)
# Write out files ####
saveRDS(mlp_model, file = "processed_data/non_neuronal/8_training_mlp/mlpwdml_model.RDS")

# print session Info ####
sessionInfo()
```

```{bash filename="8_training_mlp_nonneuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=8_training_mlp_nonneuronal
#SBATCH --output=logs/non_neuronal/8_training_mlp_nonneuronal.out
#SBATCH --error=logs/non_neuronal/8_training_mlp_nonneuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=medium
#SBATCH --time=50:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/non_neuronal/8_training_mlp_nonneuronal.R
```


#### Model Evaluation 
As with pan-cellular models, overall accuracy and sensitivity and specificity were assessed for each model. Each cell type-specific model was evaluated using its respective cell type testing partition.

###### Neuronal
```{r filename="9_evaluation_overall_neuronal.R"}
# Setup ####
## libraries
library(Seurat)
library(randomForest)
library(kernlab)
library(RSNNS)
library(caret)
library(ROCR)
library(pROC)
library(ggplot2)
library(dplyr)
library(tidyr)

## set seed
set.seed(1234)

## data
### gene chromosome data
Rn7.gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
Rn7.gtf <- as.data.frame(Rn7.gtf)

### models
lr_model <- readRDS("processed_data/neuronal/5_training_logistic_regression/lr_model.RDS")
rf_model <- readRDS("processed_data/neuronal/6_training_random_forest/rf_model.RDS")
svm_model <- readRDS("processed_data/neuronal/7_training_svm/svm_rad_model.RDS")
mlp_model <- readRDS("processed_data/neuronal/8_training_mlp/mlpwdml_model.RDS")

### testing data
#### testing object
testing_obj <- readRDS("processed_data/12_create_splits_celltype_specific/Rn7_VTA_testing_neuronal.RDS")
#### count matrix
testing <- read.csv("processed_data/neuronal/4_feature_selection_Boruta/test_count_data.csv", row.names = 1)
#### make character ID bin
testing$Identity_bin_char <- recode(testing$Identity_bin, `0` = "Male", `1` = "Female")
testing$Identity_bin_char <- factor(testing$Identity_bin_char, levels = c("Male", "Female"))
#### make ID bin a factor
testing$Identity_bin <- as.factor(testing$Identity_bin)

# Baseline Classifiers ####
## chr Y
y.count <- function(srat.object){
  # load gene expression count data
  srat.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA"))))
  
  # load gene annotations
  Rn7.gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
  Rn7.gtf <- as.data.frame(Rn7.gtf)
  
  # select Y chromosome genes
  y.genes <- Rn7.gtf %>% #from Rn7 gene annotations
    filter(seqnames == "Y") %>% #filter for chrY only
    select(gene_id, gene_name) %>% #select gene ids and names
    mutate(gene_name = coalesce(gene_name, gene_id)) %>% #replace NA name values with gene ID
    pull(gene_name) %>% #pull gene name values
    unique() #only unique values, returns 27 genes
  
  # create cumulative expresion of Y genes
  y.counts <- srat.counts %>%
    select(any_of(y.genes)) %>%
    rowSums()

  return(y.counts)
}
## Xist
Xist.count <- function(srat.object){
  # load gene expression count data
  Xist.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA")))) %>%
    pull("Xist")
  
  return(Xist.counts)
}

# Predictions ####
## logistic regression
lr_prediction <- predict(lr_model,testing[,1:(ncol(testing)-2)], type = "response")
## support vector machine
svm_prediction <- predict(svm_model,testing[,1:(ncol(testing)-2)], type = "prob")
## random forrest
rf_prediction <- predict(rf_model,testing[,1:(ncol(testing)-2)], type = "prob")
## multi-layer perceptron
mlp_prediction <- predict(mlp_model,testing[,1:(ncol(testing)-2)], type = "prob")
## chrY expression based prediction
chrY_prediction <- y.count(testing_obj)
## Xist expression based prediction
Xist_prediction <- Xist.count(testing_obj)


# ROC curves ####
## calculate ROC
lr_roc <- roc(testing$Identity_bin,lr_prediction, levels = c(1,0))
svm_roc <- roc(testing$Identity_bin_char, svm_prediction[,2], levels = c("Female", "Male"))
rf_roc <- roc(testing$Identity_bin_char, rf_prediction[,2], levels = c("Female", "Male"))
mlp_roc <- roc(testing$Identity_bin_char, mlp_prediction[,2], levels = c("Female", "Male"))
chrY_roc <- roc(testing$Identity_bin_char, chrY_prediction, levels = c("Female", "Male"))
Xist_roc <- roc(testing$Identity_bin_char, Xist_prediction, levels = c("Female", "Male"), direction = ">")

## plot ROC curves
g <- ggroc(data = list(`Chr Y` = chrY_roc,
                       `Xist` = Xist_roc,
                       `Logistic Regression` = lr_roc,
                       `SVM` = svm_roc,
                       `Random Forest` = rf_roc,
                       `MLP` = mlp_roc), legacy.axes = TRUE) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(color = "Model") +
  theme_bw()
ggsave(filename = "plots/neuronal/9_evaluation_overall/ROC_curves.pdf",
       plot = g + theme(text = element_text(size = 20)),
       height = 10,
       width = 12,
       device = "pdf")

## save AUC values
auc.table <- data.frame(AUC = c(chrY_roc[["auc"]] %>% as.numeric(),
                                Xist_roc[["auc"]] %>% as.numeric(),
                                lr_roc[["auc"]] %>% as.numeric(),
                                svm_roc[["auc"]] %>% as.numeric(),
                                rf_roc[["auc"]] %>% as.numeric(),
                                mlp_roc[["auc"]] %>% as.numeric()))
rownames(auc.table) <- c("Chr Y",
                         "Xist",
                         "Logistic Regression",
                         "SVM",
                         "Random Forest",
                         "MLP")
write.csv(auc.table, "processed_data/neuronal/9_evaluation_overall/AUCs_table.csv")

# Confusion Matrices ####
## make precitions using threshold
svm_prediction$class <- ifelse(svm_prediction$Female >0.5, "Female", "Male")
svm_prediction$class <- factor(svm_prediction$class, levels = c("Male", "Female"))

rf_prediction$class <- ifelse(rf_prediction$Female >0.5, "Female", "Male")
rf_prediction$class <- factor(rf_prediction$class, levels = c("Male", "Female"))

mlp_prediction$class <- ifelse(mlp_prediction$Female >0.5, "Female", "Male")
mlp_prediction$class <- factor(mlp_prediction$class, levels = c("Male", "Female"))

lr_prediction <- ifelse(lr_prediction >0.5, 1, 0)
lr_prediction <- as.factor(lr_prediction)

chrY_class <- ifelse(chrY_prediction > 0.5, "Male", "Female")
chrY_class <- factor(chrY_class, levels = c("Male", "Female"))

Xist_class <- ifelse(Xist_prediction < 0.5, "Male", "Female")
Xist_class <- factor(Xist_class, levels = c("Male", "Female"))


## make confusion matrices
svm_confusion <- caret::confusionMatrix(svm_prediction$class,testing$Identity_bin_char)
rf_confusion <- caret::confusionMatrix(rf_prediction$class,testing$Identity_bin_char)
mlp_confusion <- caret::confusionMatrix(mlp_prediction$class,testing$Identity_bin_char)
lr_confusion <- caret::confusionMatrix(lr_prediction, testing$Identity_bin)
chrY_confusion <- caret::confusionMatrix(chrY_class, testing$Identity_bin_char)
Xist_confusion <- caret::confusionMatrix(Xist_class, testing$Identity_bin_char)

## print confusion matrices to log
print("SVM confusion Matrix: ")
svm_confusion
cat("\n")

print("Random Forest confusion Matrix: ")
rf_confusion
cat("\n")

print("MLP confusion matrix: ")
mlp_confusion
cat("\n")

print("Logistic Regression confusion matrix: ")
lr_confusion
cat("\n")

print("Chr Y confusion matrix: ")
chrY_confusion
cat("\n")

print("Xist confusion matrix: ")
Xist_confusion
cat("\n")

## make accuracy table
acc.table <- data.frame(Accuracy = c(chrY_confusion[["overall"]][["Accuracy"]],
                                     Xist_confusion[["overall"]][["Accuracy"]],
                                     lr_confusion[["overall"]][["Accuracy"]],
                                     svm_confusion[["overall"]][["Accuracy"]],
                                     rf_confusion[["overall"]][["Accuracy"]],
                                     mlp_confusion[["overall"]][["Accuracy"]]))
rownames(acc.table) <- c("Chr Y",
                         "Xist",
                         "Logistic Regression",
                         "SVM",
                         "Random Forest",
                         "MLP")
write.csv(acc.table, "processed_data/neuronal/9_evaluation_overall/Accuracy_table.csv")

## stacked bar plot of prediction accuracies
### make list of confusion matrices
confusion.list <- list(ChrY = chrY_confusion,
                       Xist = Xist_confusion,
                       `Logistic Regression` = lr_confusion,
                       SVM = svm_confusion,
                       `Random Forest` = rf_confusion,
                       MLP = mlp_confusion)

### extract values to data frame with values for reference_prediction
confusion.df <- data.frame(model = c("Chr Y","Xist", "Logistic Regression", "SVM", "Random Forest", "MLP"),
                           Male_correct = lapply(confusion.list, function(x){x[["table"]][1,1]}) %>% unlist(),
                           Female_incorrect = lapply(confusion.list, function(x){x[["table"]][1,2]}) %>% unlist(),
                           Male_incorrect = lapply(confusion.list, function(x){x[["table"]][2,1]}) %>% unlist(),
                           Female_correct = lapply(confusion.list, function(x){x[["table"]][2,2]}) %>% unlist())

### convert to long format and split reference level and prediction
confusion.df.long <- confusion.df %>%
  pivot_longer(cols = Male_correct:Female_correct,
               names_to = "prediction",
               values_to = "count") %>%
  separate(col = prediction,
           into = c("reference","prediction"),
           sep = "_")

### convert variables to factors
confusion.df.long <- confusion.df.long %>% mutate(reference = factor(reference, levels = c("Male", "Female")),
                                                  prediction = factor(prediction, levels = c("incorrect","correct")),
                                                  model = factor(model, levels = rev(c("Chr Y","Xist", "Logistic Regression", "SVM", "Random Forest", "MLP"))))

### create stacked bar plot of predictions split by sex
confusion.plot <- ggplot(data = confusion.df.long, mapping = aes(x=model, y=count, fill=prediction)) + 
  scale_fill_manual(values = c(correct = "#00A651", incorrect = "#000000")) +
  geom_bar(position="fill", stat="identity") +
  facet_wrap( ~ reference) +
  theme_bw() +
  coord_flip() +
  labs(title = "Confuson plot", x = "Model", y = "Proportion") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())

### save
ggsave(plot = confusion.plot,
       file = "plots/neuronal/9_evaluation_overall/confusionplot.pdf",
       height = 7,
       width = 10,
       device = "pdf")

# sessionInfo
sessionInfo()
```

```{bash filename="9_evaluation_overall_neuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=9_evaluation_overall_neuronal
#SBATCH --output=logs/neuronal/9_evaluation_overall_neuronal.out
#SBATCH --error=logs/neuronal/9_evaluation_overall_neuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@mail.edu

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/neuronal/9_evaluation_overall_neuronal.R
```

###### Non-neuronal
```{r filename="9_evaluation_overall_nonneuronal.R"}
# Setup ####
## libraries
library(Seurat)
library(randomForest)
library(kernlab)
library(RSNNS)
library(caret)
library(ROCR)
library(pROC)
library(ggplot2)
library(dplyr)
library(tidyr)

## set seed
set.seed(1234)

## data
### gene chromosome data
Rn7.gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
Rn7.gtf <- as.data.frame(Rn7.gtf)

### models
lr_model <- readRDS("processed_data/non_neuronal/5_training_logistic_regression/lr_model.RDS")
rf_model <- readRDS("processed_data/non_neuronal/6_training_random_forest/rf_model.RDS")
svm_model <- readRDS("processed_data/non_neuronal/7_training_svm/svm_rad_model.RDS")
mlp_model <- readRDS("processed_data/non_neuronal/8_training_mlp/mlpwdml_model.RDS")

### testing data
#### testing object
testing_obj <- readRDS("processed_data/12_create_splits_celltype_specific/Rn7_VTA_testing_nonneuronal.RDS")
#### count matrix
testing <- read.csv("processed_data/non_neuronal/4_feature_selection_Boruta/test_count_data.csv", row.names = 1)
#### make character ID bin
testing$Identity_bin_char <- recode(testing$Identity_bin, `0` = "Male", `1` = "Female")
testing$Identity_bin_char <- factor(testing$Identity_bin_char, levels = c("Male", "Female"))
#### make ID bin a factor
testing$Identity_bin <- as.factor(testing$Identity_bin)

# Baseline Classifiers ####
## chr Y
y.count <- function(srat.object){
  # load gene expression count data
  srat.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA"))))
  
  # load gene annotations
  Rn7.gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
  Rn7.gtf <- as.data.frame(Rn7.gtf)
  
  # select Y chromosome genes
  y.genes <- Rn7.gtf %>% #from Rn7 gene annotations
    filter(seqnames == "Y") %>% #filter for chrY only
    select(gene_id, gene_name) %>% #select gene ids and names
    mutate(gene_name = coalesce(gene_name, gene_id)) %>% #replace NA name values with gene ID
    pull(gene_name) %>% #pull gene name values
    unique() #only unique values, returns 27 genes
  
  # create cumulative expresion of Y genes
  y.counts <- srat.counts %>%
    select(any_of(y.genes)) %>%
    rowSums()

  return(y.counts)
}
## Xist
Xist.count <- function(srat.object){
  # load gene expression count data
  Xist.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA")))) %>%
    pull("Xist")
  
  return(Xist.counts)
}

# Predictions ####
## logistic regression
lr_prediction <- predict(lr_model,testing[,1:(ncol(testing)-2)], type = "response")
## support vector machine
svm_prediction <- predict(svm_model,testing[,1:(ncol(testing)-2)], type = "prob")
## random forrest
rf_prediction <- predict(rf_model,testing[,1:(ncol(testing)-2)], type = "prob")
## multi-layer perceptron
mlp_prediction <- predict(mlp_model,testing[,1:(ncol(testing)-2)], type = "prob")
## chrY expression based prediction
chrY_prediction <- y.count(testing_obj)
## Xist expression based prediction
Xist_prediction <- Xist.count(testing_obj)


# ROC curves ####
## calculate ROC
lr_roc <- roc(testing$Identity_bin,lr_prediction, levels = c(1,0))
svm_roc <- roc(testing$Identity_bin_char, svm_prediction[,2], levels = c("Female", "Male"))
rf_roc <- roc(testing$Identity_bin_char, rf_prediction[,2], levels = c("Female", "Male"))
mlp_roc <- roc(testing$Identity_bin_char, mlp_prediction[,2], levels = c("Female", "Male"))
chrY_roc <- roc(testing$Identity_bin_char, chrY_prediction, levels = c("Female", "Male"))
Xist_roc <- roc(testing$Identity_bin_char, Xist_prediction, levels = c("Female", "Male"), direction = ">")

## plot ROC curves
g <- ggroc(data = list(`Chr Y` = chrY_roc,
                       `Xist` = Xist_roc,
                       `Logistic Regression` = lr_roc,
                       `SVM` = svm_roc,
                       `Random Forest` = rf_roc,
                       `MLP` = mlp_roc), legacy.axes = TRUE) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(color = "Model") +
  theme_bw()
ggsave(filename = "plots/non_neuronal/9_evaluation_overall/ROC_curves.pdf",
       plot = g + theme(text = element_text(size = 20)),
       height = 10,
       width = 12,
       device = "pdf")

## save AUC values
auc.table <- data.frame(AUC = c(chrY_roc[["auc"]] %>% as.numeric(),
                                Xist_roc[["auc"]] %>% as.numeric(),
                                lr_roc[["auc"]] %>% as.numeric(),
                                svm_roc[["auc"]] %>% as.numeric(),
                                rf_roc[["auc"]] %>% as.numeric(),
                                mlp_roc[["auc"]] %>% as.numeric()))
rownames(auc.table) <- c("Chr Y",
                         "Xist",
                         "Logistic Regression",
                         "SVM",
                         "Random Forest",
                         "MLP")
write.csv(auc.table, "processed_data/non_neuronal/9_evaluation_overall/AUCs_table.csv")

# Confusion Matrices ####
## make precitions using threshold
svm_prediction$class <- ifelse(svm_prediction$Female >0.5, "Female", "Male")
svm_prediction$class <- factor(svm_prediction$class, levels = c("Male", "Female"))

rf_prediction$class <- ifelse(rf_prediction$Female >0.5, "Female", "Male")
rf_prediction$class <- factor(rf_prediction$class, levels = c("Male", "Female"))

mlp_prediction$class <- ifelse(mlp_prediction$Female >0.5, "Female", "Male")
mlp_prediction$class <- factor(mlp_prediction$class, levels = c("Male", "Female"))

lr_prediction <- ifelse(lr_prediction >0.5, 1, 0)
lr_prediction <- as.factor(lr_prediction)

chrY_class <- ifelse(chrY_prediction > 0.5, "Male", "Female")
chrY_class <- factor(chrY_class, levels = c("Male", "Female"))

Xist_class <- ifelse(Xist_prediction < 0.5, "Male", "Female")
Xist_class <- factor(Xist_class, levels = c("Male", "Female"))


## make confusion matrices
svm_confusion <- caret::confusionMatrix(svm_prediction$class,testing$Identity_bin_char)
rf_confusion <- caret::confusionMatrix(rf_prediction$class,testing$Identity_bin_char)
mlp_confusion <- caret::confusionMatrix(mlp_prediction$class,testing$Identity_bin_char)
lr_confusion <- caret::confusionMatrix(lr_prediction, testing$Identity_bin)
chrY_confusion <- caret::confusionMatrix(chrY_class, testing$Identity_bin_char)
Xist_confusion <- caret::confusionMatrix(Xist_class, testing$Identity_bin_char)

## print confusion matrices to log
print("SVM confusion Matrix: ")
svm_confusion
cat("\n")

print("Random Forest confusion Matrix: ")
rf_confusion
cat("\n")

print("MLP confusion matrix: ")
mlp_confusion
cat("\n")

print("Logistic Regression confusion matrix: ")
lr_confusion
cat("\n")

print("Chr Y confusion matrix: ")
chrY_confusion
cat("\n")

print("Xist confusion matrix: ")
Xist_confusion
cat("\n")

## make accuracy table
acc.table <- data.frame(Accuracy = c(chrY_confusion[["overall"]][["Accuracy"]],
                                     Xist_confusion[["overall"]][["Accuracy"]],
                                     lr_confusion[["overall"]][["Accuracy"]],
                                     svm_confusion[["overall"]][["Accuracy"]],
                                     rf_confusion[["overall"]][["Accuracy"]],
                                     mlp_confusion[["overall"]][["Accuracy"]]))
rownames(acc.table) <- c("Chr Y",
                         "Xist",
                         "Logistic Regression",
                         "SVM",
                         "Random Forest",
                         "MLP")
write.csv(acc.table, "processed_data/non_neuronal/9_evaluation_overall/Accuracy_table.csv")

## stacked bar plot of prediction accuracies
### make list of confusion matrices
confusion.list <- list(ChrY = chrY_confusion,
                       Xist = Xist_confusion,
                       `Logistic Regression` = lr_confusion,
                       SVM = svm_confusion,
                       `Random Forest` = rf_confusion,
                       MLP = mlp_confusion)

### extract values to data frame with values for reference_prediction
confusion.df <- data.frame(model = c("Chr Y","Xist", "Logistic Regression", "SVM", "Random Forest", "MLP"),
                           Male_correct = lapply(confusion.list, function(x){x[["table"]][1,1]}) %>% unlist(),
                           Female_incorrect = lapply(confusion.list, function(x){x[["table"]][1,2]}) %>% unlist(),
                           Male_incorrect = lapply(confusion.list, function(x){x[["table"]][2,1]}) %>% unlist(),
                           Female_correct = lapply(confusion.list, function(x){x[["table"]][2,2]}) %>% unlist())

### convert to long format and split reference level and prediction
confusion.df.long <- confusion.df %>%
  pivot_longer(cols = Male_correct:Female_correct,
               names_to = "prediction",
               values_to = "count") %>%
  separate(col = prediction,
           into = c("reference","prediction"),
           sep = "_")

### convert variables to factors
confusion.df.long <- confusion.df.long %>% mutate(reference = factor(reference, levels = c("Male", "Female")),
                                                  prediction = factor(prediction, levels = c("incorrect","correct")),
                                                  model = factor(model, levels = rev(c("Chr Y","Xist", "Logistic Regression", "SVM", "Random Forest", "MLP"))))

### create stacked bar plot of predictions split by sex
confusion.plot <- ggplot(data = confusion.df.long, mapping = aes(x=model, y=count, fill=prediction)) + 
  scale_fill_manual(values = c(correct = "#00A651", incorrect = "#000000")) +
  geom_bar(position="fill", stat="identity") +
  facet_wrap( ~ reference) +
  theme_bw() +
  coord_flip() +
  labs(title = "Confuson plot", x = "Model", y = "Proportion") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())

### save
ggsave(plot = confusion.plot,
       file = "plots/non_neuronal/9_evaluation_overall/confusionplot.pdf",
       height = 7,
       width = 10,
       device = "pdf")

# sessionInfo
sessionInfo()
```

```{bash filename="9_evaluation_overall_nonneuronal.sh"}
#!/bin/bash
#
#SBATCH --job-name=9_evaluation_overall_nonneuronal
#SBATCH --output=logs/non_neuronal/9_evaluation_overall_nonneuronal.out
#SBATCH --error=logs/non_neuronal/9_evaluation_overall_nonneuronal.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@mail.edu

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/non_neuronal/9_evaluation_overall_nonneuronal.R
```


### NAc Evaluation
Performance on new or unseen data, called generalizability, is a critical measure of a model's utility. To validate that models learned robust cell sex classification rules that could be applied to other datasets, we measured the AUC-ROC and accuracy of model predictions in an orthogonal snRNA-seq experiment from the rat nucleus accumbens (NAc) [Phillips et al, 2023](https://doi.org/10.1016/j.mcn.2023.103849). Unlike the VTA, the NAc is largely composed of GABAergic medium spiny neurons (in addition to cholinergic and GABAergic interneurons), yet also contains similar glial cell types. This dataset contains 39,252 cells of 16 transcriptionally defined cell types from 32 rats (16M/16F). Similar to the VTA data set, we will need to add gene counts for Xist after re-processing this data with a genome annotation file including *Xist*.

```{r filename="13_evaluation_NAc.R"}
# Setup ####
# libraries
library(Seurat)
library(caret)
library(randomForest)
library(kernlab)
library(RSNNS)
library(ROCR)
library(pROC)
library(ggplot2)
library(dplyr)
library(tidyr)

# set seet
set.seed(1234)

# Data
## gene chromosome data
Rn7.gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
Rn7.gtf <- as.data.frame(Rn7.gtf)

# Process NAc data ####
# Load NAc data
## NAc w/o Xist
NAc_noXist <- readRDS("raw_data/NAc_Combo_Integrated.RDS")
## Acute data w/ Xist
acute <- list(
  Fem_Sal  = Read10X(data.dir = "2019-JD-0037/Ensembl_Rn7_Xist/FemSal_output_Rn7_Xist/outs/filtered_feature_bc_matrix/"),
  Fem_Coc  = Read10X(data.dir = "2019-JD-0037/Ensembl_Rn7_Xist/FemCoc_output_Rn7_Xist/outs/filtered_feature_bc_matrix/"),
  Male_Sal = Read10X(data.dir = "2019-JD-0037/Ensembl_Rn7_Xist/MaleSal_output_Rn7_Xist/outs/filtered_feature_bc_matrix/"),
  Male_Coc = Read10X(data.dir = "2019-JD-0037/Ensembl_Rn7_Xist/MaleCoc_output_Rn7_Xist/outs/filtered_feature_bc_matrix/")
)
## Repeated data w/ Xist
repeated <- list(
  Fem_Sal  = Read10X(data.dir = "2019-JD-0040/Ensembl_Rn7_Xist/1_1_output_Rn7_Xist/outs/filtered_feature_bc_matrix/"),
  Fem_Coc  = Read10X(data.dir = "2019-JD-0040/Ensembl_Rn7_Xist/2_1_output_Rn7_Xist/outs/filtered_feature_bc_matrix/"),
  Male_Sal = Read10X(data.dir = "2019-JD-0040/Ensembl_Rn7_Xist/3_1_output_Rn7_Xist/outs/filtered_feature_bc_matrix/"),
  Male_Coc = Read10X(data.dir = "2019-JD-0040/Ensembl_Rn7_Xist/4_1_output_Rn7_Xist/outs/filtered_feature_bc_matrix/")
)

# Create Seurat objects
acute <- lapply(acute, function(x) {
  CreateSeuratObject(counts = x, project = "Acute", min.cells = 0, min.features = 0)
})
repeated <- lapply(repeated, function(x) {
  CreateSeuratObject(counts = x, project = "Repeated", min.cells = 0, min.features = 0)
})

# Add metadata
acute_names <- names(acute)
acute <- lapply(names(acute), function(x) {
  acute[[x]]$Dataset <- "Acute"
  acute[[x]]$Sex_Stim <- x
  return(acute[[x]])
})
names(acute) <- acute_names

repeated_names <- names(repeated)
repeated <- lapply(names(repeated), function(x) {
  repeated[[x]]$Dataset <- "Repeated"
  repeated[[x]]$Sex_Stim <- x
  return(repeated[[x]])
})
names(repeated) <- repeated_names

# determine the appropriate sample tags from the !Xist object so cells can be matched
extract_tags <- function(metadata) {
  # Extract the tag from the cell names
  metadata$Tag <- sub(".*-1", "", rownames(metadata))
  
  # Group by Dataset and Sex_Stim and get the unique tag for each combination
  result <- metadata %>%
    dplyr::group_by(Dataset, Sex_Stim) %>%
    dplyr::summarize(Tag = unique(Tag), .groups = "drop")
  
  return(result)
}

sample_tags <- extract_tags(NAc_noXist@meta.data)
# Dataset  Sex_Stim Tag  
# 1 Acute    Fem_Coc  _2_1 
# 2 Acute    Fem_Sal  _1_1 
# 3 Acute    Male_Coc _4_1 
# 4 Acute    Male_Sal _3_1 
# 5 Repeated Fem_Coc  _2_2 
# 6 Repeated Fem_Sal  _1_2 
# 7 Repeated Male_Coc _4_2 
# 8 Repeated Male_Sal _3_2 

# Append tags to acute and repeated data cell names
acute <- lapply(acute, function(x) {
  # Get the corresponding tag from the sample_tags data frame
  tag <- sample_tags$Tag[sample_tags$Dataset == x$Dataset[1] & sample_tags$Sex_Stim == x$Sex_Stim[1]]
  
  # Append the tag to the cell names
  x <- RenameCells(x, new.names = paste0(colnames(x), tag))
  return(x)
})
repeated <- lapply(repeated, function(x) {
  # Get the corresponding tag from the sample_tags data frame
  tag <- sample_tags$Tag[sample_tags$Dataset == x$Dataset[1] & sample_tags$Sex_Stim == x$Sex_Stim[1]]
  
  # Append the tag to the cell names
  x <- RenameCells(x, new.names = paste0(colnames(x), tag))
  return(x)
})

# Verify that the tags were added correctly, and match a subset of the orignial data
acute_cells <- lapply(acute, function(x) {
  matching_cells <- NAc_noXist@meta.data %>%
    filter(Dataset == x$Dataset[1] & Sex_Stim == x$Sex_Stim[1]) %>%
    rownames()
  cells <- Cells(x)[Cells(x) %in% matching_cells]
  return(cells)
})
repeated_cells <- lapply(repeated, function(x) {
  matching_cells <- NAc_noXist@meta.data %>%
    filter(Dataset == x$Dataset[1] & Sex_Stim == x$Sex_Stim[1]) %>%
    rownames()
  cells <- Cells(x)[Cells(x) %in% matching_cells]
  return(cells)
})
## create a list of all cells that are shared between Rn7_Xist and the Xist added data
shared_cells <- c(unlist(acute_cells), unlist(repeated_cells))

# Extract raw Xist counts from the acute and repeated data
Xist_acute <- lapply(names(acute), FUN = function(x,y) {
  xist_counts <- LayerData(acute[[x]], "counts", cells = acute_cells[[x]], features = "Xist")
  return(xist_counts)
})
names(Xist_acute) <- acute_names

Xist_repeated <- lapply(names(repeated), function(x) {
  xist_counts <- LayerData(repeated[[x]], "counts", cells = repeated_cells[[x]], features = "Xist")
  return(xist_counts)
})
names(Xist_repeated) <- repeated_names

## Combine acute and repeated data
Xist_counts <- do.call(cbind, c(Xist_acute, Xist_repeated))

# Extract raw counts from NAc_noXist data
NAc_noXist_counts <- LayerData(NAc_noXist, "counts", cells = shared_cells)
## Merge Xist counts with NAc_noXist counts
NAc_Xist_counts <- rbind(NAc_noXist_counts, Xist_counts)

# Create a new Seurat object with the merged counts
NAc_Xist <- CreateSeuratObject(counts = NAc_Xist_counts, project = "NAc_Xist")
## Add metadata
NAc_Xist$Dataset <- NAc_noXist$Dataset[rownames(NAc_Xist@meta.data)]
NAc_Xist$Sex <- NAc_noXist$Sex[rownames(NAc_Xist@meta.data)]
NAc_Xist$Stim <- NAc_noXist$Stim[rownames(NAc_Xist@meta.data)]
NAc_Xist$Sex_Stim <- NAc_noXist$Sex_Stim[rownames(NAc_Xist@meta.data)]
NAc_Xist$CellType <- NAc_noXist$CellType[rownames(NAc_Xist@meta.data)]
## Normalise data
NAc_Xist <- NormalizeData(NAc_Xist, normalization.method = "LogNormalize", scale.factor = 10000)
## Scale data
NAc_Xist <- ScaleData(NAc_Xist, verbose = FALSE)
## Save object
saveRDS(NAc_Xist, file = "processed_data/13_evaluation_NAc/NAc_Xist.RDS")


# Evaluate Model Performance ####
# Trained models
lr_model <- readRDS("processed_data/5_training_logistic_regression/lr_model.RDS")
rf_model <- readRDS("processed_data/6_training_random_forest/rf_model.RDS")
svm_model <- readRDS("processed_data/7_training_svm/svm_rad_model.RDS")
mlp_model <- readRDS("processed_data/8_training_mlp/mlpwdml_model.RDS")

# Baseline models
## Chr Y
y.count <- function(srat.object){
  # load gene expression count data
  srat.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA"))))
  
  # load gene annotations
  Rn7.gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
  Rn7.gtf <- as.data.frame(Rn7.gtf)
  
  # select Y chromosome genes
  y.genes <- Rn7.gtf %>% #from Rn7 gene annotations
    filter(seqnames == "Y") %>% #filter for chrY only
    select(gene_id, gene_name) %>% #select gene ids and names
    mutate(gene_name = coalesce(gene_name, gene_id)) %>% #replace NA name values with gene ID
    pull(gene_name) %>% #pull gene name values
    unique() #only unique values, returns 27 genes
  
  # create cumulative expresion of Y genes
  y.counts <- srat.counts %>%
    select(any_of(y.genes)) %>%
    rowSums()
  
  return(y.counts)
}
## Xist
Xist.count <- function(srat.object){
  # load gene expression count data
  Xist.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA")))) %>%
    pull("Xist")
  
  return(Xist.counts)
}

# Create count data subset for models
confirmed.genes <- read.csv("processed_data/4_feature_selection_Boruta/Boruta_final_decisions.csv") %>% 
  filter(finalDecision == "Confirmed") %>%
  pull(variable)

NAc_df <- LayerData(NAc_Xist, "data", features = confirmed.genes) %>%
  as.matrix() %>%
  t() %>%
  as.data.frame() %>%
  mutate(Identity_bin_char = factor(NAc_Xist$Sex, levels = c("Male", "Female")),
         Identity_bin = Identity_bin_char %>% as.numeric() - 1)

## replace "-" in gene names with "."
colnames(NAc_df) <- gsub("-", ".", colnames(NAc_df))

## Predictions ####
# logistic regression
lr_prediction <- predict(lr_model,NAc_df[,1:(ncol(NAc_df)-2)], type = "response")
# support vector machine
svm_prediction <- predict(svm_model,NAc_df[,1:(ncol(NAc_df)-2)], type = "prob")
# random forrest
rf_prediction <- predict(rf_model,NAc_df[,1:(ncol(NAc_df)-2)], type = "prob")
# multi-layer perceptron
mlp_prediction <- predict(mlp_model,NAc_df[,1:(ncol(NAc_df)-2)], type = "prob")
# chrY expression based prediction
chrY_prediction <- y.count(NAc_Xist)
# Xist expression based prediction
Xist_prediction <- Xist.count(NAc_Xist)


## ROC curves ####
# calculate ROC
lr_roc <- roc(NAc_df$Identity_bin,lr_prediction, levels = c(1,0))
svm_roc <- roc(NAc_df$Identity_bin_char, svm_prediction[,2], levels = c("Female", "Male"))
rf_roc <- roc(NAc_df$Identity_bin_char, rf_prediction[,2], levels = c("Female", "Male"))
mlp_roc <- roc(NAc_df$Identity_bin_char, mlp_prediction[,2], levels = c("Female", "Male"))
chrY_roc <- roc(NAc_df$Identity_bin_char, chrY_prediction, levels = c("Female", "Male"))
Xist_roc <- roc(NAc_df$Identity_bin_char, Xist_prediction, levels = c("Female", "Male"), direction = ">")

# plot ROC curves
g <- ggroc(data = list(`Chr Y` = chrY_roc,
                       `Xist` = Xist_roc,
                       `Logistic Regression` = lr_roc,
                       `SVM` = svm_roc,
                       `Random Forest` = rf_roc,
                       `MLP` = mlp_roc), legacy.axes = TRUE) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(color = "Model") +
  theme_bw()
ggsave(filename = "plots/13_evaluation_NAc/ROC_curves.pdf",
       plot = g + theme(text = element_text(size = 20)),
       height = 10,
       width = 12,
       device = "pdf")

## save AUC values
auc.table <- data.frame(AUC = c(chrY_roc[["auc"]] %>% as.numeric(),
                                Xist_roc[["auc"]] %>% as.numeric(),
                                lr_roc[["auc"]] %>% as.numeric(),
                                svm_roc[["auc"]] %>% as.numeric(),
                                rf_roc[["auc"]] %>% as.numeric(),
                                mlp_roc[["auc"]] %>% as.numeric()))
rownames(auc.table) <- c("Chr Y",
                         "Xist",
                         "Logistic Regression",
                         "SVM",
                         "Random Forest",
                         "MLP")
write.csv(auc.table, "processed_data/13_evaluation_NAc/AUCs_table.csv")

## Confusion Matrices ####
# make precitions using threshold
svm_prediction$class <- ifelse(svm_prediction$Female >0.5, "Female", "Male")
svm_prediction$class <- factor(svm_prediction$class, levels = c("Male", "Female"))

rf_prediction$class <- ifelse(rf_prediction$Female >0.5, "Female", "Male")
rf_prediction$class <- factor(rf_prediction$class, levels = c("Male", "Female"))

mlp_prediction$class <- ifelse(mlp_prediction$Female >0.5, "Female", "Male")
mlp_prediction$class <- factor(mlp_prediction$class, levels = c("Male", "Female"))

lr_prediction <- ifelse(lr_prediction >0.5, 1, 0)
lr_prediction <- as.factor(lr_prediction)

chrY_class <- ifelse(chrY_prediction > 0.5, "Male", "Female")
chrY_class <- factor(chrY_class, levels = c("Male", "Female"))

Xist_class <- ifelse(Xist_prediction < 0.5, "Male", "Female")
Xist_class <- factor(Xist_class, levels = c("Male", "Female"))


# make confusion matrices
svm_confusion <- caret::confusionMatrix(svm_prediction$class,NAc_df$Identity_bin_char)
rf_confusion <- caret::confusionMatrix(rf_prediction$class,NAc_df$Identity_bin_char)
mlp_confusion <- caret::confusionMatrix(mlp_prediction$class,NAc_df$Identity_bin_char)
lr_confusion <- caret::confusionMatrix(lr_prediction, as.factor(NAc_df$Identity_bin))
chrY_confusion <- caret::confusionMatrix(chrY_class, NAc_df$Identity_bin_char)
Xist_confusion <- caret::confusionMatrix(Xist_class, NAc_df$Identity_bin_char)

## print confusion matrices to log
print("SVM confusion Matrix: ")
svm_confusion
cat("\n")

print("Random Forest confusion Matrix: ")
rf_confusion
cat("\n")

print("MLP confusion matrix: ")
mlp_confusion
cat("\n")

print("Logistic Regression confusion matrix: ")
lr_confusion
cat("\n")

print("Chr Y confusion matrix: ")
chrY_confusion
cat("\n")

print("Xist confusion matrix: ")
Xist_confusion
cat("\n")

## make accuracy table
acc.table <- data.frame(Accuracy = c(chrY_confusion[["overall"]][["Accuracy"]],
                                     Xist_confusion[["overall"]][["Accuracy"]],
                                     lr_confusion[["overall"]][["Accuracy"]],
                                     svm_confusion[["overall"]][["Accuracy"]],
                                     rf_confusion[["overall"]][["Accuracy"]],
                                     mlp_confusion[["overall"]][["Accuracy"]]))
rownames(acc.table) <- c("Chr Y",
                         "Xist",
                         "Logistic Regression",
                         "SVM",
                         "Random Forest",
                         "MLP")
write.csv(acc.table, "processed_data/13_evaluation_NAc/Accuracy_table.csv")

## stacked bar plot of prediction accuracies
### make list of confusion matrices
confusion.list <- list(ChrY = chrY_confusion,
                       Xist = Xist_confusion,
                       `Logistic Regression` = lr_confusion,
                       SVM = svm_confusion,
                       `Random Forest` = rf_confusion,
                       MLP = mlp_confusion)

### extract values to data frame with values for reference_prediction
confusion.df <- data.frame(model = c("Chr Y","Xist", "Logistic Regression", "SVM", "Random Forest", "MLP"),
                           Male_correct = lapply(confusion.list, function(x){x[["table"]][1,1]}) %>% unlist(),
                           Female_incorrect = lapply(confusion.list, function(x){x[["table"]][1,2]}) %>% unlist(),
                           Male_incorrect = lapply(confusion.list, function(x){x[["table"]][2,1]}) %>% unlist(),
                           Female_correct = lapply(confusion.list, function(x){x[["table"]][2,2]}) %>% unlist())

### convert to long format and split reference level and prediction
confusion.df.long <- confusion.df %>%
  pivot_longer(cols = Male_correct:Female_correct,
               names_to = "prediction",
               values_to = "count") %>%
  separate(col = prediction,
           into = c("reference","prediction"),
           sep = "_")

### convert variables to factors
confusion.df.long <- confusion.df.long %>% mutate(reference = factor(reference, levels = c("Male", "Female")),
                                                  prediction = factor(prediction, levels = c("incorrect","correct")),
                                                  model = factor(model, levels = rev(c("Chr Y","Xist", "Logistic Regression", "SVM", "Random Forest", "MLP"))))

### create stacked bar plot of predictions split by sex
confusion.plot <- ggplot(data = confusion.df.long, mapping = aes(x=model, y=count, fill=prediction)) + 
  scale_fill_manual(values = c(correct = "#00A651", incorrect = "#000000")) +
  geom_bar(position="fill", stat="identity") +
  facet_wrap( ~ reference) +
  theme_bw() +
  coord_flip() +
  labs(title = "Confuson plot", x = "Model", y = "Proportion") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())

### save
ggsave(plot = confusion.plot,
       file = "plots/13_evaluation_NAc/confusionplot.pdf",
       height = 7,
       width = 10,
       device = "pdf")

# sessionInfo
sessionInfo()
```

```{bash filename="13_evaluation_NAc.sh"}
#!/bin/bash
#
#SBATCH --job-name=13_evaluation_NAc
#SBATCH --output=logs/13_evaluation_NAc.out
#SBATCH --error=logs/13_evaluation_NAc.err
#SBATCH --ntasks=1
#SBATCH --partition=short
#SBATCH --time=4:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/13_evaluation_NAc.R
```


### Thresholding
Models predict cell sex probabilities form 0 (likely male) to 1 (likely female), enabling us to refine our overall accuracy by omitting tenuous predictions near the clasification threshold of 0.5. To assess the number of cells omitted and improvements to accuracy for different thresholds, we evaluated two thresholds centered around 0.5: narrow (0.4-0.6) and wide (0.25-0.75). To apply these thresholds, we make classifications with the LR model as usual and simply count the number of cells falling inside/outside each threshold as well as the accuracy of predicitons inside/outside each threshold.

```{r filename="14_thresholding_LR.R"}
# Setup ####
# Libraries
library(SeuratObject)
library(Seurat)
library(caret)
library(ROCR)
library(pROC)
library(ggplot2)
library(dplyr)
library(tidyr)
library(magrittr)

# Data
## testing object
testing_obj <- readRDS("processed_data/2_create_splits/Rn7_VTA_testing.RDS")
## count matrix
testing <- read.csv("processed_data/4_feature_selection_Boruta/test_count_data.csv", row.names = 1)
## make character ID bin
testing$Identity_bin_char <- recode(testing$Identity_bin, `0` = "Male", `1` = "Female")
testing$Identity_bin_char <- factor(testing$Identity_bin_char, levels = c("Male", "Female"))
## make ID bin a factor
testing$Identity_bin <- as.factor(testing$Identity_bin)
## make cell type column
testing$CellType <- testing_obj$CellType


### logistic regression model
lr_model <- readRDS("processed_data/5_training_logistic_regression/lr_model.RDS")

# Make test data set predictions ####
lr_prediction <- predict(lr_model,testing[,1:(ncol(testing)-3)], type = "response")
lr_prediction_df <- data.frame(cell = names(lr_prediction),
                               prediction = lr_prediction,
                               binarized = ifelse(lr_prediction >0.5, 1, 0),
                               character = ifelse(lr_prediction >0.5, "Female", "Male") %>% as.factor(),
                               real = (as.numeric(testing$Identity_bin)-1),
                               celltype = testing$CellType,
                               GEM_Well = testing_obj$GEM_Well)
lr_prediction_df <- lr_prediction_df %>% 
  mutate(correct = binarized == real)

# Evaluate prediction thresholds using test data ####
thresholding_stats_df <- data.frame(threshold = c(0,0.1, 0.25),
                                    ncell_included = c(nrow(lr_prediction_df),
                                                       lr_prediction_df %>% filter(prediction < 0.4 | prediction > 0.6) %>% nrow(),
                                                       lr_prediction_df %>% filter(prediction < 0.25 | prediction > 0.75) %>% nrow()),
                                    ncell_excluded = c(0,
                                                       nrow(lr_prediction_df) - lr_prediction_df %>% filter(prediction < 0.4 | prediction > 0.6) %>% nrow(),
                                                       nrow(lr_prediction_df) - lr_prediction_df %>% filter(prediction < 0.25 | prediction > 0.75) %>% nrow()),
                                    nfemale_included = c(lr_prediction_df %>% pull(real) %>% sum(),
                                                         lr_prediction_df %>% filter(prediction < 0.4 | prediction > 0.6) %>% pull(real) %>% sum(),
                                                         lr_prediction_df %>% filter(prediction < 0.25 | prediction > 0.75) %>% pull(real) %>% sum()),
                                    nfemale_excluded = c(0,
                                                         lr_prediction_df %>% filter(prediction > 0.4 & prediction < 0.6) %>% pull(real) %>% sum(),
                                                         lr_prediction_df %>% filter(prediction > 0.25 & prediction < 0.75) %>% pull(real) %>% sum()),
                                    acc_included = c(lr_prediction_df %>%
                                                       pull(correct) %>%
                                                       sum() / lr_prediction_df %>% nrow(),
                                                     lr_prediction_df %>%
                                                       filter(prediction < 0.4 | prediction > 0.6) %>%
                                                       pull(correct) %>% sum() / lr_prediction_df %>% filter(prediction < 0.4 | prediction > 0.6) %>% nrow(),
                                                     lr_prediction_df %>%
                                                       filter(prediction < 0.25 | prediction > 0.75) %>%
                                                       pull(correct) %>% sum() / lr_prediction_df %>% filter(prediction < 0.25 | prediction > 0.75) %>% nrow()),
                                    acc_excluded = c(NA,
                                                     lr_prediction_df %>%
                                                       filter(prediction > 0.4 & prediction < 0.6) %>%
                                                       pull(correct) %>% sum() / lr_prediction_df %>% filter(prediction > 0.4 & prediction < 0.6) %>% nrow(),
                                                     lr_prediction_df %>%
                                                       filter(prediction > 0.25 & prediction < 0.75) %>%
                                                       pull(correct) %>% sum() / lr_prediction_df %>% filter(prediction > 0.25 & prediction < 0.75) %>% nrow())
)

## Plot test data class prediction distribution
test.hist <- ggplot(data = lr_prediction_df, aes(x = prediction)) +
  geom_histogram(binwidth = 0.05, fill = "grey") +
  ylim(c(0,3800)) +
  labs(title = "Test Data: Class Prediction Probabilities (bin size = 5)",
       x = "probability",
       y = "count") +
  theme_bw()

## Plot test data class predicitons with thresholds
test.hist.threshold <- ggplot(data = lr_prediction_df, aes(x = prediction)) +
  geom_histogram(binwidth = 0.05, fill = "grey") +
  ylim(c(0,3800)) +
  geom_vline(xintercept = 0.25, color = "red", linetype = "dotted") +
  geom_vline(xintercept = 0.75, color = "red", linetype = "dotted") +
  geom_vline(xintercept = 0.4, color = "blue", linetype = "dotted") +
  geom_vline(xintercept = 0.6, color = "blue", linetype = "dotted") +
  labs(title = "Test Data: Class Prediction Probabilities (bin size = 5)",
       x = "probability",
       y = "count") +
  theme_bw()

### plot distribution of false classifications
test_false.hist.threshold <- lr_prediction_df %>% filter(correct == F) %>% 
  ggplot(aes(x = prediction)) +
  geom_histogram(binwidth = 0.05, fill = "grey") +
  ylim(c(0,3800)) +
  geom_vline(xintercept = 0.25, color = "red", linetype = "dotted") +
  geom_vline(xintercept = 0.75, color = "red", linetype = "dotted") +
  geom_vline(xintercept = 0.4, color = "blue", linetype = "dotted") +
  geom_vline(xintercept = 0.6, color = "blue", linetype = "dotted") +
  labs(title = "Test Data: Class Prediction Probabilities (bin size = 5)",
       x = "probability",
       y = "count") +
  theme_bw()

test_false.hist.threshold.scaled <- lr_prediction_df %>% filter(correct == F) %>% 
  ggplot(aes(x = prediction)) +
  geom_histogram(binwidth = 0.05, fill = "grey") +
  #ylim(c(0,3800)) +
  geom_vline(xintercept = 0.25, color = "red", linetype = "dotted") +
  geom_vline(xintercept = 0.75, color = "red", linetype = "dotted") +
  geom_vline(xintercept = 0.4, color = "blue", linetype = "dotted") +
  geom_vline(xintercept = 0.6, color = "blue", linetype = "dotted") +
  labs(title = "Test Data: Class Prediction Probabilities (bin size = 5)",
       x = "probability",
       y = "count") +
  theme_bw()

### plot distributions of true and false classifications
test_double.hist.threshold <- lr_prediction_df %>%
  ggplot(aes(x = prediction, fill = correct)) +
  geom_histogram(binwidth = 0.05, position = 'stack') +
  scale_fill_manual(values=c("black", "#00A651")) +
  geom_vline(xintercept = 0.25, color = "red", linetype = "dotted") +
  geom_vline(xintercept = 0.75, color = "red", linetype = "dotted") +
  geom_vline(xintercept = 0.4, color = "blue", linetype = "dotted") +
  geom_vline(xintercept = 0.6, color = "blue", linetype = "dotted") +
  labs(title = "Test Data: Class Prediction Probabilities (bin size = 0.05)",
       x = "probability",
       y = "count") +
  theme_bw()

## Plot test data class binarized predicitons
test.hist.binarized <- ggplot(data = lr_prediction_df, aes(x = binarized)) +
  geom_histogram(binwidth = 0.05, fill = "grey") +
  ylim(c(0,3800)) +
  labs(title = "Test Data: Class Prediction binarized (bin size = 5)",
       x = "probability",
       y = "count") +
  theme_bw()

test.hist.true <- ggplot(data = lr_prediction_df, aes(x = (as.numeric(real)-1))) +
  geom_histogram(binwidth = 0.05, fill = "grey") +
  ylim(c(0,3800)) +
  labs(title = "Test Data: True Class Identities (bin size = 5)",
       x = "probability",
       y = "count") +
  theme_bw()

## Affected cell types
### Test data
test_celltypes <- table(testing$CellType) %>% data.frame()
test_celltypes <- test_celltypes %>% 
  mutate(exclude.10 = lr_prediction_df %>% 
           filter(prediction > 0.4 & prediction < 0.6) %$% 
           table(.$celltype) %>% data.frame() %>% pull(Freq),
         exclude.25 = lr_prediction_df %>% 
           filter(prediction > 0.25 & prediction < 0.75) %$% 
           table(.$celltype) %>% data.frame() %>% pull(Freq))

test_celltype.hist <- lr_prediction_df %>% 
  mutate(neuronal = ifelse(celltype %in% c("Glut-Neuron-1", "GABA-Neuron-1", "Glut-Neuron-2", "GABA-Neuron-2", "DA-Neuron", "GABA-Neuron-3", "Glut-Neuron-3"), "Neuronal", "Non-neuronal")) %>% 
  ggplot(aes(x = prediction, fill = neuronal)) +
  geom_histogram(binwidth = 0.05, position = 'stack') +
  scale_fill_manual(values=c("#624185", "#FFA345")) +
  geom_vline(xintercept = 0.25, color = "red", linetype = "dotted") +
  geom_vline(xintercept = 0.75, color = "red", linetype = "dotted") +
  geom_vline(xintercept = 0.4, color = "blue", linetype = "dotted") +
  geom_vline(xintercept = 0.6, color = "blue", linetype = "dotted") +
  labs(title = "Test Data: Class Prediction Probabilities (bin size = 0.05)",
       x = "probability",
       y = "count") +
  theme_bw()

# Save output
## accuracy w/ different thresholds
write.csv(thresholding_stats_df, file = "processed_data/14_thresholding_LR/LR_threshold_test_stats.csv")
## ncells per cell type excluded by decision buffer
write.csv(test_celltypes, file = "processed_data/14_thresholding_LR/LR_test_ncells.csv")

## test data predicted probability distribution w/o thresholds
ggsave(plot = test.hist,
       filename = "plots/14_thresholding_LR/LR_test_prediction_hist.pdf",
       device = "pdf",
       height = 6,
       width = 10)

## test data predicted probability distribution w/ thresholds
ggsave(plot = test.hist.threshold,
       filename = "plots/14_thresholding_LR/LR_test_prediction_threshold_hist.pdf",
       device = "pdf",
       height = 6,
       width = 10)

## test data false predictions distribution w/ threshold unscaled
ggsave(plot = test_false.hist.threshold,
       filename = "plots/14_thresholding_LR/LR_test_prediction_false_hist.pdf",
       device = "pdf",
       height = 6,
       width = 10)

## test data false predictions distribution w/ threshold scaled
ggsave(plot = test_false.hist.threshold.scaled,
       filename = "plots/14_thresholding_LR/LR_test_prediction_false_hist_scaled.pdf",
       device = "pdf",
       height = 6,
       width = 10)

## test data predicted probability distribution binarized
ggsave(plot = test.hist.binarized,
       filename = "plots/14_thresholding_LR/LR_test_prediction_binarized_hist.pdf",
       device = "pdf",
       height = 6,
       width = 10)

## test data predicted probability distribution true vals
ggsave(plot = test.hist.true,
       filename = "plots/14_thresholding_LR/LR_test_prediction_true_hist.pdf",
       device = "pdf",
       height = 6,
       width = 10)

## NAc data predicted probability distributions for true/false classifications
ggsave(plot = test_double.hist.threshold,
       filename = "plots/14_thresholding_LR/LR_test_prediction_true_false_hist.pdf",
       device = "pdf",
       height = 6,
       width = 10)

## NAc data predicted probability distributions for neuronal/non-neuronal classifications
ggsave(plot = test_celltype.hist,
       filename = "plots/14_thresholding_LR/LR_test_prediction_celltype_hist.pdf",
       device = "pdf",
       height = 6,
       width = 10)

# Session info ####
sessionInfo()
```

```{bash filename="14_thresholding_LR.sh"}
#!/bin/bash
#
#SBATCH --job-name=14_thresholding_LR
#SBATCH --output=logs/14_thresholding_LR.out
#SBATCH --error=logs/14_thresholding_LR.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/14_thresholding_LR.R
```


### Depth vs Accuracy
To determine if the UMI count (unique molecular index) per cell was associated with model accuracy, we used logistic regression analysis. Logistic regression models were fit for VTA test partition cell UMI count and model classification accuracy (correct: 1, incorrect: 0) for all sex prediction models. The fit models were used to determine the UMI count at which the probability of a correct model classification reached 95%.

```{r filename="15_depth_accuracy.R"}
# Setup ####
# libraries
library(Seurat)
library(caret)
library(randomForest)
library(kernlab)
library(RSNNS)
library(ROCR)
library(pROC)
library(ggplot2)
library(dplyr)
library(tidyr)
library(patchwork)

### models
lr_model <- readRDS("processed_data/5_training_logistic_regression/lr_model.RDS")
rf_model <- readRDS("processed_data/6_training_random_forest/rf_model.RDS")
svm_model <- readRDS("processed_data/7_training_svm/svm_rad_model.RDS")
mlp_model <- readRDS("processed_data/8_training_mlp/mlpwdml_model.RDS")

### testing data
#### full object
full_obj <- readRDS("raw_data/Rn7_VTA.RDS")
#### testing object
testing_obj <- readRDS("processed_data/2_create_splits/Rn7_VTA_testing.RDS")
#### fix nCount_RNA
testing_obj$nCount_RNA <- full_obj$nCount_RNA[Cells(testing_obj)]
#### count matrix
testing <- read.csv("processed_data/4_feature_selection_Boruta/test_count_data.csv", row.names = 1)
#### make character ID bin
testing$Identity_bin_char <- recode(testing$Identity_bin, `0` = "Male", `1` = "Female")
testing$Identity_bin_char <- factor(testing$Identity_bin_char, levels = c("Male", "Female"))
#### make ID bin a factor
testing$Identity_bin <- as.factor(testing$Identity_bin)
#### add neuronal/nonneuronal celltype column
testing_obj@meta.data <- testing_obj@meta.data %>% 
  mutate(Neuronal = case_when(CellType %in% c("Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3", "DA-Neuron") ~ "Neuronal",
                              CellType %in% c("Olig-1", "Olig-2", "Olig-3", "Astrocyte", "Polydendrocyte", "Microglia", "OPC-Olig-1", "Mural", "Endothelial") ~ "Non-Neuronal"))


# Baseline Classifiers ####
## chr Y
y.count <- function(srat.object){
  # load gene expression count data
  srat.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA"))))
  
  # load gene annotations
  Rn7.gtf <- rtracklayer::import("raw_data/Rattus_norvegicus.mRatBN7.2.105.Xist.gtf")
  Rn7.gtf <- as.data.frame(Rn7.gtf)
  
  # select Y chromosome genes
  y.genes <- Rn7.gtf %>% #from Rn7 gene annotations
    filter(seqnames == "Y") %>% #filter for chrY only
    select(gene_id, gene_name) %>% #select gene ids and names
    mutate(gene_name = coalesce(gene_name, gene_id)) %>% #replace NA name values with gene ID
    pull(gene_name) %>% #pull gene name values
    unique() #only unique values, returns 27 genes
  
  # create cumulative expresion of Y genes
  y.counts <- srat.counts %>%
    select(any_of(y.genes)) %>%
    rowSums()
  
  return(y.counts)
}
## Xist
Xist.count <- function(srat.object){
  # load gene expression count data
  Xist.counts <- as.data.frame(t(as.matrix(GetAssayData(object = srat.object, slot = "data", assay = "RNA")))) %>%
    pull("Xist")
  
  return(Xist.counts)
}

# Predictions ####
# class probabilities
## logistic regression
lr_prediction <- predict(lr_model,testing[,1:(ncol(testing)-2)], type = "response")
## support vector machine
svm_prediction <- predict(svm_model,testing[,1:(ncol(testing)-2)], type = "prob")
## random forest
rf_prediction <- predict(rf_model,testing[,1:(ncol(testing)-2)], type = "prob")
## multi-layer perceptron
mlp_prediction <- predict(mlp_model,testing[,1:(ncol(testing)-2)], type = "prob")
## chrY expression based prediction
chrY_prediction <- y.count(testing_obj)
## Xist expression based prediction
Xist_prediction <- Xist.count(testing_obj)

# binary classification
## logistic regression
lr_class <- ifelse(lr_prediction >0.5, "Female", "Male")
lr_class <- factor(lr_class, levels = c("Male", "Female"))
## support vector machine
svm_prediction$class <- ifelse(svm_prediction$Female >0.5, "Female", "Male")
svm_prediction$class <- factor(svm_prediction$class, levels = c("Male", "Female"))
## random forest
rf_prediction$class <- ifelse(rf_prediction$Female >0.5, "Female", "Male")
rf_prediction$class <- factor(rf_prediction$class, levels = c("Male", "Female"))
## multi-layer perceptron
mlp_prediction$class <- ifelse(mlp_prediction$Female >0.5, "Female", "Male")
mlp_prediction$class <- factor(mlp_prediction$class, levels = c("Male", "Female"))
## chrY expression based prediction
chrY_class <- ifelse(chrY_prediction > 0.5, "Male", "Female")
chrY_class <- factor(chrY_class, levels = c("Male", "Female"))
## Xist expression based prediction
Xist_class <- ifelse(Xist_prediction < 0.5, "Male", "Female")
Xist_class <- factor(Xist_class, levels = c("Male", "Female"))

# Aggregate results ####
acc.depth.df <- data.frame(cell = row.names(testing),
                           celltype = testing_obj$Neuronal,
                           RNA = testing_obj$nCount_RNA,
                           sex = testing_obj$Sex,
                           chrY = chrY_class,
                           Xist = Xist_class,
                           lr = lr_class,
                           svm = svm_prediction$class,
                           rf = rf_prediction$class,
                           mlp = mlp_prediction$class)

## change predictions to correct?(T/F)
acc.depth.df <- acc.depth.df %>% 
  mutate(chrY = case_when(chrY == sex ~ 1,
                          chrY != sex ~ 0),
         Xist = case_when(Xist == sex ~ 1,
                          Xist != sex ~ 0),
         lr   = case_when(lr == sex ~ 1,
                          lr != sex ~ 0),
         svm  = case_when(svm == sex ~ 1,
                          svm != sex ~ 0),
         rf   = case_when(rf == sex ~ 1,
                          rf != sex ~ 0),
         mlp  = case_when(mlp == sex ~ 1,
                          mlp != sex ~ 0))

# Plot accuracy depth ####
## calculate logistic regressions for read depth and classification
fits <- list(chrY = glm(chrY ~ RNA, data = acc.depth.df, family = "binomial"),
             Xist = glm(Xist ~ RNA, data = acc.depth.df, family = "binomial"),
             lr = glm(lr ~ RNA, data = acc.depth.df, family = "binomial"),
             svm = glm(svm ~ RNA, data = acc.depth.df, family = "binomial"),
             rf = glm(rf ~ RNA, data = acc.depth.df, family = "binomial"),
             mlp = glm(mlp ~ RNA, data = acc.depth.df, family = "binomial"))

## collect results in data frame
model.intercept <- sapply(fits, function(x){coef(summary(x))[1,]}) %>% t() %>% data.frame()
model.intercept$model <- row.names(model.intercept)
colnames(model.intercept) <- c("Intercept_Estimate", "Intercept_StdErr", "Intercept_Z", "Interpect_pval", "model")

model.RNA <- sapply(fits, function(x){coef(summary(x))[2,]}) %>% t() %>% data.frame()
model.RNA$model <- row.names(model.RNA)
colnames(model.RNA) <- c("RNA_Estimate", "RNA_StdErr", "RNA_Z", "RNA_pval", "model")

results.df <- left_join(x = model.intercept,
                        y = model.RNA,
                        by = "model" ) %>% 
  select(model, Intercept_Estimate, Intercept_StdErr, Intercept_Z, Interpect_pval, RNA_Estimate, RNA_StdErr, RNA_Z, RNA_pval)

## calculate read depth at which probability of correct prediction is 95%
critical <- lapply(fits, function(model){
  ### Given values
  intercept <- model[["coefficients"]][["(Intercept)"]]
  coef_RNA <- model[["coefficients"]][["RNA"]]
  target_probability <- 0.95
  
  ### Define the equation to solve
  equation <- function(RNA) {
    p <- 1 / (1 + exp(-(intercept + coef_RNA * RNA)))
    return(p - target_probability)
  }
  
  ### Use uniroot to find the RNA value
  result <- uniroot(equation, c(0, 80000))  # Adjust the range as needed
  
  ### The result contains the RNA value
  return(round(result$root))
})

## make plots
theme_set(theme_bw())
theme_update(panel.grid.minor = element_blank(),
             panel.grid.major = element_blank(),
             panel.border = element_rect(colour = "black"),
             text = element_text(size = 10),
             axis.title = element_text(size = 8),
             axis.text = element_text(size = 7))

plots <- list(
  chrY_plot = ggplot(data = acc.depth.df,
                     mapping = aes(x = RNA, y = chrY)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                method.args = list(family = "binomial"), se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$chrY, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$chrY, 0, 20000, 40000, 60000, 80000)), guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "Chr Y", x = "RNA count", y = "Classification"),
  
  Xist_plot = ggplot(data = acc.depth.df,
                     mapping = aes(x = RNA, y = Xist)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                method.args = list(family = "binomial"), se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$Xist, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$Xist, 0, 20000, 40000, 60000, 80000)),guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "Xist", x = "RNA count", y = "Classification"),
  
  lr_plot = ggplot(data = acc.depth.df,
                   mapping = aes(x = RNA, y = lr)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                method.args = list(family = "binomial"), se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$lr, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$lr, 0, 20000, 40000, 60000, 80000)), guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "LR", x = "RNA count", y = "Classification"),
  
  svm_plot = ggplot(data = acc.depth.df,
                    mapping = aes(x = RNA, y = svm)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                method.args = list(family = "binomial"), se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$svm, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$svm, 0 ,20000, 40000, 60000, 80000)), guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "SVM", x = "RNA count", y = "Classification"),
  rf_plot = ggplot(data = acc.depth.df,
                   mapping = aes(x = RNA, y = rf)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                method.args = list(family = "binomial"), se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$rf, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$rf, 0, 20000, 40000, 60000, 80000)), guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "RF", x = "RNA count", y = "Classification"),
  mlp_plot = ggplot(data = acc.depth.df,
                    mapping = aes(x = RNA, y = mlp)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                method.args = list(family = "binomial"), se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$mlp, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$mlp, 0, 20000, 40000, 60000, 80000)), guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "MLP", x = "RNA count", y = "Classification"))

## Arrange plots into figure
figure <- plots$chrY_plot + plots$Xist_plot + plots$lr_plot + plots$svm_plot + plots$rf_plot + plots$mlp_plot +
  plot_layout(ncol = 2)

# log scaled ####
plots.log <- list(
  chrY_plot = ggplot(data = acc.depth.df,
                     mapping = aes(x = RNA, y = chrY)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                formula = y ~ I(10^x),
                method.args = list(family = "binomial"),
                se = F) + 
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$chrY, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$chrY, 0, 500, 1000,  5000, 10000, 50000)),
                       trans = "log10", guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "Chr Y", x = "RNA count", y = "Classification"),
  
  Xist_plot = ggplot(data = acc.depth.df,
                     mapping = aes(x = RNA, y = Xist)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                formula = y ~ I(10^x),
                method.args = list(family = "binomial"),
                se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$Xist, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$Xist, 0, 500, 1000,  5000, 10000, 50000)),
                       trans = "log10", guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "Xist", x = "RNA count", y = "Classification"),
  lr_plot = ggplot(data = acc.depth.df,
                   mapping = aes(x = RNA, y = lr)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                formula = y ~ I(10^x),
                method.args = list(family = "binomial"),
                se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$lr, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$lr, 0, 500, 1000,  5000, 10000, 50000)),
                       trans = "log10", guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "LR", x = "RNA count", y = "Classification"),
  svm_plot = ggplot(data = acc.depth.df,
                    mapping = aes(x = RNA, y = svm)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                formula = y ~ I(10^x),
                method.args = list(family = "binomial"),
                se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$svm, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$svm, 0, 500, 1000,  5000, 10000, 50000)),
                       trans = "log10", guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "SVM", x = "RNA count", y = "Classification"),
  rf_plot = ggplot(data = acc.depth.df,
                   mapping = aes(x = RNA, y = rf)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                formula = y ~ I(10^x),
                method.args = list(family = "binomial"),
                se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$rf, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$rf, 0, 500, 1000,  5000, 10000, 50000)),
                       trans = "log10", guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "RF", x = "RNA count", y = "Classification"),
  mlp_plot = ggplot(data = acc.depth.df,
                    mapping = aes(x = RNA, y = mlp)) +
    geom_point(shape = 1) +
    geom_smooth(method = "glm",
                formula = y ~ I(10^x),
                method.args = list(family = "binomial"),
                se = F) +
    geom_hline(yintercept =  0.95, linetype = "dashed", color = "red") +
    geom_vline(xintercept =  critical$mlp, linetype = "dashed", color = "red") +
    scale_x_continuous(breaks = sort(c(critical$mlp, 0, 500, 1000,  5000, 10000, 50000)),
                       trans = "log10", guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.95, 1)) +
    labs(title = "MLP", x = "RNA count", y = "Classification"))

## Arrange plots into figure
figure.log <- plots.log$chrY_plot + plots.log$Xist_plot + plots.log$lr_plot + plots.log$svm_plot + plots.log$rf_plot + plots.log$mlp_plot +
  plot_layout(ncol = 2)


#Save outputs
# logistic regression estimates
write.csv(results.df,
          file = "processed_data/15_evaluation_depth_accuracy/depth_vs_acc.celltype.coeff.csv",
          row.names = F)

## non-scaled
pdf(file = "plots/15_evaluation_depth_accuracy/depth_vs_acc.VTA.allmodels.pdf",
    width = 8,
    height = 8)
figure
dev.off()

## log10 scaled
pdf(file = "plots/15_evaluation_depth_accuracy/depth_vs_acc.log.VTA.allmodels.pdf",
    width = 8,
    height = 8)
figure.log
dev.off()

# sessionInfo ####
sessionInfo()
```

```{bash filename="15_depth_accuracy.sh"}
#!/bin/bash
#
#SBATCH --job-name=15_depth_accuracy
#SBATCH --output=logs/15_depth_accuracy.out
#SBATCH --error=logs/15_depth_accuracy.err
#SBATCH --ntasks=1
#SBATCH --partition=express
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@domain

# Load Modules
module load R/4.2.0-foss-2022b 

# Run script
Rscript code/15_depth_accuracy.R
```

### Additional Plotting
#### Feature selection
To get an idea of how our feature selection results look, we make a few plots that capture the important parts of our selection process.

First, we plot a heatmap of our sex dependent DEGs' log2 fold changes across clusters. Log2 fold changes are calculated by seurat as the average expression in females +1 divided by the average expression in males +1. The pseudocount of 1 is added to avoid dividing by and taking the log of zero. Plotting this gives us an idea of the magnitude of changes and how these are reflected across cell types. A number of genes are only significant and/or tested in a subset of cell types, for genes not tested, we can calculate their fold change values again using the seurat `FindMarkers()` function.

We'll also plot the results of our feature selection using Boruta. For each of the 3000 iterations run, Boruta ascertains the importance of each feature and shadow feature to determine their final decision as important or not. Boruta has a built in plot functionality that generates boxplots for the distribution of  each gene's importance results across all iterations, and orders these boxplots by their median importance. Here we implement a similar plotting strategy using ggplot for easier customization. Plotting this gives us a quick and easy way to view the proportions of "confirmed" and "rejected" genes, as well as their trends in importance.
```{r filename="feature_selection_plotting.R"}
# Setup ####
# libraries
library(Seurat)
library(Boruta)
library(dplyr)
library(tidyr)
library(ggplot2)
library(plotly)
library(forcats)

# seed
set.seed(1234)

# data
### Training object
training.obj <- readRDS("processed_data/2_create_splits/Rn7_VTA_training.RDS") 

## DEGs
### full results
degs.full <- read.csv("processed_data/3_feature_selection_DEGs/DEGs_sex_cluster_VTA_full.csv") %>% 
  mutate(Cluster= factor(Cluster, levels = c("DA-Neuron",
                                             "Glut-Neuron-1",
                                             "Glut-Neuron-2",
                                             "Glut-Neuron-3",
                                             "GABA-Neuron-1",
                                             "GABA-Neuron-2",
                                             "GABA-Neuron-3",
                                             "Olig-1",
                                             "Olig-2",
                                             "Olig-3",
                                             "Astrocyte",
                                             "Microglia",
                                             "Polydendrocyte",
                                             "OPC-Olig-1",
                                             "Mural",
                                             "Endothelial")))
### significant results
degs.sig <- degs.full %>% filter(p_val_adj < 0.05)
### significant results gene names
degs.sig.genes <- degs.sig %>% 
  pull(GeneName) %>% 
  unique()
### names of clusters
degs.sig.cluster <- degs.sig %>% 
  pull(Cluster) %>% 
  unique()

## Boruta
boruta.obj <- readRDS("processed_data/4_feature_selection_Boruta/VTA_Boruta_max3000.RDS")
boruta.obj.fix <- TentativeRoughFix(boruta.obj)
selected.genes <- read.csv("processed_data/4_feature_selection_Boruta/Boruta_final_decisions.csv") %>% 
  filter(finalDecision == "Confirmed") %>% 
  pull("variable")


# DEG plotting ####
Idents(training.obj) <- training.obj$CellType_Sex

## fill in lfc values for significant genes, across clusters
### initialize results list
lfc.df <- vector(mode = "list",length = 16)
names(lfc.df) <- levels(training.obj$CellType)
for(i in names(lfc.df)){
  lfc.df[[i]] <- FindMarkers(object = training.obj,
                             ident.1 = paste0(i,"_Female"),
                             ident.2 = paste0(i,"_Male"),
                             logfc.threshold = 0,
                             min.pct = 0,
                             min.cells.group = 0)
}
### flatten list
lfc.df <- do.call(what = rbind,lfc.df)
### Create an ID column that is the rownames
lfc.df$ID <- rownames(lfc.df)
### Add gene names and cluster
lfc.df <- separate(lfc.df, col = ID, into = c("Cluster", "GeneName"), sep = "\\.", remove = FALSE, extra = "merge")
### filter for significant results
lfc.df <- lfc.df %>% 
  filter(GeneName %in% degs.sig.genes)
### make complete df
deg.df.full <- expand.grid(Cluster = levels(degs.sig.cluster),
                           GeneName = degs.sig.genes)
deg.df.full <- left_join(x = deg.df.full,
                         y = degs.sig %>% select(Cluster, GeneName, avg_log2FC),
                         by = c("Cluster", "GeneName"),
                         keep = F,
                         relationship = "one-to-one")
deg.df.full <- left_join(deg.df.full,
                         y = lfc.df %>% select(Cluster, GeneName, avg_log2FC),
                         by = c("Cluster", "GeneName"),
                         keep = F,
                         relationship = "one-to-one")

deg.df.full.coalesce <- deg.df.full %>% 
  mutate(avg_log2FC = coalesce(avg_log2FC.x, avg_log2FC.y)) %>% 
  select(Cluster, GeneName, avg_log2FC) %>% 
  mutate(Cluster= factor(Cluster, levels = c("DA-Neuron",
                                             "Glut-Neuron-1",
                                             "Glut-Neuron-2",
                                             "Glut-Neuron-3",
                                             "GABA-Neuron-1",
                                             "GABA-Neuron-2",
                                             "GABA-Neuron-3",
                                             "Olig-1",
                                             "Olig-2",
                                             "Olig-3",
                                             "Astrocyte",
                                             "Microglia",
                                             "Polydendrocyte",
                                             "OPC-Olig-1",
                                             "Mural",
                                             "Endothelial") %>% rev()))

## plot heatmap
degs.plot.hm <- ggplot(deg.df.full.coalesce , aes(x = Cluster, y = fct_reorder(GeneName, avg_log2FC, mean), fill = avg_log2FC)) +
  geom_tile() +
  scale_fill_gradient2(
    low = "#00BFC4",
    mid = "white",
    high = "#F8766D",
    midpoint = 0,
    limits = c(-2.5,2.5),
    oob = scales::squish) +
  labs(x = "Cell Type", y = "Gene", fill = "Log2 FC") +
  coord_flip() +
  theme(axis.text.x = element_blank(),
        panel.background = element_blank())

## save outs
ggsave(plot = degs.plot.hm,
       filename = "plots/feature_selection_plotting/deg.sig.heatmap.pdf",
       height = 5,
       width = 10,
       units = "in",
       device = "pdf")
ggsave(plot = degs.plot.hm,
       filename = "plots/feature_selection_plotting/deg.sig.heatmap.png",
       height = 5,
       width = 10,
       units = "in",
       dpi = 300,
       device = "png")
write.csv(lfc.df,
          file = "processed_data/feature_selection_plotting/unfiltered_deg_results.csv",
          row.names = F)
write.csv(deg.df.full.coalesce,
          file = "processed_data/feature_selection_plotting/lfc_sig_allclusters.csv", 
          row.names = F)


# Boruta ####
#ggplotting code from https://stackoverflow.com/questions/73415232/how-to-use-ggplot2-to-plot-box-plots-from-borutas-results-in-r
## object manipulation
### create list of importance histories for each gene
lz <- lapply(1:ncol(boruta.obj.fix$ImpHistory),
             function(i) boruta.obj.fix$ImpHistory[is.finite(boruta.obj.fix$ImpHistory[,i]),i])
### set names for each gene list
names(lz) <- colnames(boruta.obj.fix$ImpHistory) 
### set order for list items to be decreasing by median importance
ii <- order(sapply(lz,stats::median))
lz[ii] -> lz
### collapse to data frame
lz_df <- do.call(rbind.data.frame, lz)
df <- as.data.frame(t(lz_df))
names(df) <- names(lz)
rownames(df) <- NULL
### make vector of colors
generateCol<-function(x,colCode,col,numShadow){
  #Checking arguments
  if(is.null(col) & length(colCode)!=4)
    stop('colCode should have 4 elements.')
  #Generating col
  if(is.null(col)){
    rep(colCode[4],length(x$finalDecision)+numShadow)->cc
    cc[c(x$finalDecision=='Confirmed',rep(FALSE,numShadow))]<-colCode[1]
    cc[c(x$finalDecision=='Tentative',rep(FALSE,numShadow))]<-colCode[2]
    cc[c(x$finalDecision=='Rejected',rep(FALSE,numShadow))]<-colCode[3]
    col=cc
  }
  return(col)
}
boruta.col <- generateCol(boruta.obj.fix, c('confirmed','tentative','rejected','shadow'), NULL, 3)
boruta.col <- boruta.col[ii]
color.match <- data.frame(name = names(lz),
                          color = factor(boruta.col, levels = c("confirmed", "rejected", "tentative", "shadow")))

df.long <- df %>% 
  pivot_longer(everything()) %>% 
  mutate(name = factor(name, levels = names(df)))

df.long <- left_join(df.long,
                     color.match,
                     by = "name",
                     keep = F,
                     relationship = "many-to-one")

# gene.highlights <- c("shadowMin", "shadowMean", "shadowMax")
boruta.plot <- ggplot(df.long, aes(x = fct_reorder(name, value, median), y = value)) +
  geom_boxplot(mapping = aes(col = color), fill = "white",
               outlier.alpha = 0.5,
               outlier.size = 0.5,
               outlier.shape = NA) +
  # scale_x_discrete(breaks = gene.highlights,
  #                  labels = c("Shadow Min", "Shadow Mean", "Shadow Max")) +
  scale_color_manual(values = c("shadow" = "blue", "confirmed" = "green", "rejected" = "red", "tentative" = "yellow")) +
  labs(x = "Gene", y = "Importance", color = "Decision") +
  theme_bw() + 
  theme(legend.position = c(0.15,0.85),
        panel.grid = element_blank(),
        panel.background = element_blank(),
        axis.text.x = element_blank(),
        text = element_text(size = 15))

## plot example genes
levels(training.obj$CellType) <- c("DA-Neuron",
                                   "Glut-Neuron-1",
                                   "Glut-Neuron-2",
                                   "Glut-Neuron-3",
                                   "GABA-Neuron-1",
                                   "GABA-Neuron-2",
                                   "GABA-Neuron-3",
                                   "Olig-1",
                                   "Olig-2",
                                   "Olig-3",
                                   "Astrocyte",
                                   "Microglia",
                                   "Polydendrocyte",
                                   "OPC-Olig-1",
                                   "Mural",
                                   "Endothelial")
Idents(training.obj) <- training.obj$CellType

top_10_summary <- df.long %>%
  group_by(name) %>%
  summarize(median_value = median(value, na.rm = TRUE)) %>%
  arrange(desc(median_value)) %>%
  slice_head(n = 10)

bottom_10_summary <- df.long %>%
  group_by(name) %>%
  summarize(median_value = median(value, na.rm = TRUE)) %>%
  arrange(desc(median_value)) %>%
  slice_tail(n = 10)


genes.vln <- VlnPlot(training.obj,
                     features = c("Xist",               # Xist most important female biased gene
                                  "ENSRNOG00000065796", # Xist proxy, second important female biased gene
                                  "ENSRNOG00000060617", # Uty, most important male biased gene
                                  "Ddx3",               # second most important male biased gene
                                  "Slc27a2",            # two least important genes
                                  "Trabd2b"),
                     split.by = "Sex",
                     cols = c("#F8766D", "#00BFC4"),
                     flip = T, stack = T) + theme(legend.position = "top")

## save outs
ggsave(plot = boruta.plot,
       filename = "plots/feature_selection_plotting/boruta.decisions.pdf",
       height = 5,
       width = 10,
       units = "in",
       device = "pdf")
ggsave(plot = boruta.plot,
       filename = "plots/feature_selection_plotting/boruta.decisions.png",
       height = 5,
       width = 10,
       units = "in",
       dpi = 300,
       device = "png")
ggsave(plot = genes.vln,
       filename = "plots/feature_selection_plotting/example_gene_vln.pdf",
       height = 11,
       width = 7,
       units = "in",
       device = "pdf")

# sessionInfo ####
sessionInfo()
# R version 4.2.0 (2022-04-22)
# Platform: x86_64-pc-linux-gnu (64-bit)
# Running under: Red Hat Enterprise Linux
# 
# Matrix products: default
# BLAS/LAPACK: /data/rc/apps/rc/software/FlexiBLAS/3.2.1-GCC-12.2.0/lib64/libflexiblas.so.3.2
# 
# locale:
#   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
# [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
# 
# attached base packages:
#   [1] stats     graphics  grDevices utils     datasets  methods   base     
# 
# other attached packages:
#   [1] forcats_1.0.0      plotly_4.10.4      ggplot2_3.5.1      tidyr_1.3.1        dplyr_1.1.4        Boruta_8.0.0       Seurat_5.2.1       SeuratObject_5.0.2 sp_2.1-4          
# 
# loaded via a namespace (and not attached):
#   [1] Rtsne_0.17             colorspace_2.1-0       deldir_2.0-4           ggridges_0.5.6         RcppHNSW_0.6.0         rstudioapi_0.16.0      spatstat.data_3.1-2   
# [8] farver_2.1.2           listenv_0.9.1          ggrepel_0.9.5          RSpectra_0.16-1        codetools_0.2-20       splines_4.2.0          polyclip_1.10-6       
# [15] spam_2.11-1            jsonlite_1.8.8         ica_1.0-3              cluster_2.1.6          png_0.1-8              uwot_0.2.2             shiny_1.8.1.1         
# [22] sctransform_0.4.1      spatstat.sparse_3.1-0  compiler_4.2.0         httr_1.4.7             Matrix_1.6-5           fastmap_1.2.0          lazyeval_0.2.2        
# [29] limma_3.54.2           cli_3.6.4              later_1.3.2            htmltools_0.5.8.1      tools_4.2.0            igraph_2.0.3           dotCall64_1.1-1       
# [36] gtable_0.3.5           glue_1.8.0             RANN_2.6.1             reshape2_1.4.4         Rcpp_1.0.14            scattermore_1.2        spatstat.univar_3.0-0 
# [43] vctrs_0.6.5            presto_1.0.0           spatstat.explore_3.3-1 nlme_3.1-165           progressr_0.14.0       lmtest_0.9-40          spatstat.random_3.3-1 
# [50] stringr_1.5.1          globals_0.16.3         mime_0.12              miniUI_0.1.1.1         lifecycle_1.0.4        irlba_2.3.5.1          goftest_1.2-3         
# [57] future_1.33.2          MASS_7.3-60.0.1        zoo_1.8-12             scales_1.3.0           ragg_1.3.2             promises_1.3.0         spatstat.utils_3.0-5  
# [64] parallel_4.2.0         RColorBrewer_1.1-3     reticulate_1.38.0      pbapply_1.7-2          gridExtra_2.3          stringi_1.8.4          fastDummies_1.7.3     
# [71] systemfonts_1.1.0      rlang_1.1.5            pkgconfig_2.0.3        matrixStats_1.3.0      lattice_0.22-6         ROCR_1.0-11            purrr_1.0.4           
# [78] tensor_1.5             labeling_0.4.3         patchwork_1.2.0        htmlwidgets_1.6.4      cowplot_1.1.3          tidyselect_1.2.1       parallelly_1.37.1     
# [85] RcppAnnoy_0.0.22       plyr_1.8.9             magrittr_2.0.3         R6_2.6.1               generics_0.1.3         pillar_1.10.1          withr_3.0.2           
# [92] fitdistrplus_1.2-1     survival_3.7-0         abind_1.4-5            tibble_3.2.1           future.apply_1.11.2    crayon_1.5.3           utf8_1.2.4            
# [99] KernSmooth_2.23-24     spatstat.geom_3.3-2    grid_4.2.0             data.table_1.17.0      digest_0.6.36          xtable_1.8-4           httpuv_1.6.15         
# [106] textshaping_0.4.0      munsell_0.5.1          viridisLite_0.4.2  
```

#### VTA Dataset
```{r filename="VTA_dataset_plotting.R"}
# Setup ####
# Libraries
library(Seurat)
library(dplyr)
library(ggplot2)
library(tibble)
library(tidyr)

# Data
## Original VTA object
Rn7_VTA_og <- readRDS("raw_data/Rn7_VTA.RDS")
## training cells
Rn7_VTA.training_cells <- readRDS("processed_data/2_create_splits/traincell_vector.RDS")
## testing cells
Rn7_VTA.testing_cells <- readRDS("processed_data/2_create_splits/testcell_vector.RDS")

## Rn7_Xist subsets
Rn7_VTA <- subset(Rn7_VTA_og, cells = c(Rn7_VTA.training_cells, Rn7_VTA.testing_cells))
Rn7_VTA_training <- subset(Rn7_VTA, cells = Rn7_VTA.training_cells)
Rn7_VTA_testing <- subset(Rn7_VTA, cells = Rn7_VTA.testing_cells)

# make metadata ordered factors
celltypes <- c("DA-Neuron",
               "Glut-Neuron-1",
               "Glut-Neuron-2",
               "Glut-Neuron-3",
               "GABA-Neuron-1",
               "GABA-Neuron-2",
               "GABA-Neuron-3",
               "Olig-1",
               "Olig-2",
               "Olig-3",
               "Astrocyte",
               "Microglia",
               "Polydendrocyte",
               "OPC-Olig-1",
               "Mural",
               "Endothelial")

Rn7_VTA$CellType <- factor(Rn7_VTA$CellType, levels = celltypes)
Rn7_VTA_training$CellType <- factor(Rn7_VTA_training$CellType, levels = celltypes)
Rn7_VTA_testing$CellType <- factor(Rn7_VTA_testing$CellType, levels = celltypes)

Rn7_VTA$Sex <- factor(Rn7_VTA$Sex, levels = c("Female", "Male"))
Rn7_VTA_training$Sex <- factor(Rn7_VTA_training$Sex, levels = c("Female", "Male"))
Rn7_VTA_testing$Sex <- factor(Rn7_VTA_testing$Sex, levels = c("Female", "Male"))

# Cluster summary plotting ####
# by cluster
## all cells
Rn7_VTA@active.ident <- Rn7_VTA$CellType
all.dimplot.clusters <- DimPlot(Rn7_VTA, label = TRUE) + NoLegend()

## training
Rn7_VTA_training@active.ident <- Rn7_VTA_training$CellType
training.dimplot.clusters <- DimPlot(Rn7_VTA_training, label = TRUE) + NoLegend()

## testing
Rn7_VTA_testing@active.ident <- Rn7_VTA_testing$CellType
testing.dimplot.clusters <- DimPlot(Rn7_VTA_testing, label = TRUE) + NoLegend()

## save outputs
ggsave(plot = all.dimplot.clusters,
       file = "plots/dataset_plotting/all.UMAP.celltypes.pdf",
       device = "pdf",
       height = 10,
       width = 10)
ggsave(plot = training.dimplot.clusters,
       file = "plots/dataset_plotting/training.UMAP.celltypes.pdf",
       device = "pdf",
       height = 10,
       width = 10)
ggsave(plot = testing.dimplot.clusters,
       file = "plots/dataset_plotting/testing.UMAP.celltypes.pdf",
       device = "pdf",
       height = 10,
       width = 10)

# by sex
## all cells
Rn7_VTA@active.ident <- Rn7_VTA$Sex
all.dimplot.sex <- DimPlot(Rn7_VTA, shuffle = TRUE)

## training
Rn7_VTA_training@active.ident <- Rn7_VTA_training$Sex
training.dimplot.sex <- DimPlot(Rn7_VTA_training, shuffle = TRUE)

## testing
Rn7_VTA_testing@active.ident <- Rn7_VTA_testing$Sex
testing.dimplot.sex <- DimPlot(Rn7_VTA_testing, shuffle = TRUE)

## save outputs
ggsave(plot = all.dimplot.sex,
       file = "plots/dataset_plotting/all.UMAP.sex.pdf",
       device = "pdf",
       height = 10,
       width = 10)
ggsave(plot = training.dimplot.sex,
       file = "plots/dataset_plotting/training.UMAP.sex.pdf",
       device = "pdf",
       height = 10,
       width = 10)
ggsave(plot = testing.dimplot.sex,
       file = "plots/dataset_plotting/testing.UMAP.sex.pdf",
       device = "pdf",
       height = 10,
       width = 10)


# count ncells per cluster
## all cells
all.ncells.df <- table(Rn7_VTA$CellType) %>% # make a table of cell type counts
  data.frame() %>% # convert to dataframe
  rename("CellType" = "Var1",
         "Cells" = "Freq") %>% # rename columns
  mutate(CellType = factor(CellType, levels = c("DA-Neuron","Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3",
                                                "Olig-1", "Olig-2", "Olig-3", "Astrocyte","Microglia","Polydendrocyte","OPC-Olig-1", "Mural", "Endothelial"))) # make cell type a factor
# CellType Cells
# 1       DA-Neuron   406
# 2   Glut-Neuron-1  2999
# 3   Glut-Neuron-2   697
# 4   Glut-Neuron-3   136
# 5   GABA-Neuron-1   894
# 6   GABA-Neuron-2   506
# 7   GABA-Neuron-3   320
# 8          Olig-1  6658
# 9          Olig-2  3120
# 10         Olig-3   724
# 11      Astrocyte  2559
# 12      Microglia  1118
# 13 Polydendrocyte  1560
# 14     OPC-Olig-1   249
# 15          Mural   139
# 16    Endothelial    64

train.ncells.df <- table(Rn7_VTA_training$CellType) %>% # make a table of cell type counts
  data.frame() %>% # convert to dataframe
  rename("CellType" = "Var1",
         "Cells" = "Freq") %>% # rename columns
  mutate(CellType = factor(CellType, levels = c("DA-Neuron","Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3",
                                                "Olig-1", "Olig-2", "Olig-3", "Astrocyte","Microglia","Polydendrocyte","OPC-Olig-1", "Mural", "Endothelial"))) # make cell type a factor
# CellType Cells
# 1       DA-Neuron   285
# 2   Glut-Neuron-1  2101
# 3   Glut-Neuron-2   489
# 4   Glut-Neuron-3    96
# 5   GABA-Neuron-1   627
# 6   GABA-Neuron-2   355
# 7   GABA-Neuron-3   225
# 8          Olig-1  4661
# 9          Olig-2  2185
# 10         Olig-3   508
# 11      Astrocyte  1793
# 12      Microglia   783
# 13 Polydendrocyte  1092
# 14     OPC-Olig-1   175
# 15          Mural    98
# 16    Endothelial    46
test.ncells.df <- table(Rn7_VTA_testing$CellType) %>% # make a table of cell type counts
  data.frame() %>% # convert to dataframe
  rename("CellType" = "Var1",
         "Cells" = "Freq") %>% # rename columns
  mutate(CellType = factor(CellType, levels = c("DA-Neuron","Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3",
                                                "Olig-1", "Olig-2", "Olig-3", "Astrocyte","Microglia","Polydendrocyte","OPC-Olig-1", "Mural", "Endothelial"))) # make cell type a factor
# CellType Cells
# 1       DA-Neuron   121
# 2   Glut-Neuron-1   898
# 3   Glut-Neuron-2   208
# 4   Glut-Neuron-3    40
# 5   GABA-Neuron-1   267
# 6   GABA-Neuron-2   151
# 7   GABA-Neuron-3    95
# 8          Olig-1  1997
# 9          Olig-2   935
# 10         Olig-3   216
# 11      Astrocyte   766
# 12      Microglia   335
# 13 Polydendrocyte   468
# 14     OPC-Olig-1    74
# 15          Mural    41
# 16    Endothelial    18


# sex distribution per cluster
## proportions per cluster
all.sex.distb.df.long <- table(Rn7_VTA$CellType, Rn7_VTA$Sex) %>% # make a table of cell counts per cell type by sex
  as.data.frame.matrix() %>% # convert to dataframe
  rownames_to_column("CellType") %>% # make cell type a column
  mutate(CellType = factor(CellType, levels = c("DA-Neuron","Glut-Neuron-1", "Glut-Neuron-2", "Glut-Neuron-3", "GABA-Neuron-1", "GABA-Neuron-2", "GABA-Neuron-3",
                                                "Olig-1", "Olig-2", "Olig-3", "Astrocyte","Microglia","Polydendrocyte","OPC-Olig-1", "Mural", "Endothelial") %>% rev())) %>% # make cell type a factor
  pivot_longer(cols = Female:Male, names_to = "Sex", values_to = "count") # pivot longer for plotting

## plot 
all.prop.sexes <- ggplot(data = all.sex.distb.df.long, mapping = aes(x = CellType, y = count, fill = Sex)) +
  geom_bar(position="fill", stat="identity") +
  labs(x = "Cell Type", y = "Proportion") +
  theme_bw() +
  theme(text = element_text(size = 15),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 15),
        panel.grid = element_blank()) +
  coord_flip() +
  NoLegend()

## save plot
ggsave(plot = all.prop.sexes,
       filename = "plots/dataset_plotting/all.prop.sex.pdf",
       height = 10,
       width = 10,
       device = "pdf")

# sessionInfo ####
sessionInfo()
# R version 4.2.0 (2022-04-22)
# Platform: x86_64-pc-linux-gnu (64-bit)
# Running under: Red Hat Enterprise Linux
# 
# Matrix products: default
# BLAS/LAPACK: /data/rc/apps/rc/software/FlexiBLAS/3.2.1-GCC-12.2.0/lib64/libflexiblas.so.3.2
# 
# locale:
#   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8   
# [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C            
# [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
# 
# attached base packages:
#   [1] stats     graphics  grDevices utils     datasets  methods   base     
# 
# other attached packages:
#   [1] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1      dplyr_1.1.4        Seurat_5.2.1       SeuratObject_5.0.2 sp_2.1-4          
# 
# loaded via a namespace (and not attached):
#   [1] Rtsne_0.17             colorspace_2.1-0       deldir_2.0-4           ggridges_0.5.6         RcppHNSW_0.6.0         rstudioapi_0.16.0     
# [7] spatstat.data_3.1-2    listenv_0.9.1          farver_2.1.2           ggrepel_0.9.5          RSpectra_0.16-1        codetools_0.2-20      
# [13] splines_4.2.0          polyclip_1.10-6        spam_2.11-1            jsonlite_1.8.8         ica_1.0-3              cluster_2.1.6         
# [19] png_0.1-8              uwot_0.2.2             shiny_1.8.1.1          sctransform_0.4.1      spatstat.sparse_3.1-0  compiler_4.2.0        
# [25] httr_1.4.7             Matrix_1.6-5           fastmap_1.2.0          lazyeval_0.2.2         cli_3.6.4              later_1.3.2           
# [31] htmltools_0.5.8.1      tools_4.2.0            igraph_2.0.3           dotCall64_1.1-1        gtable_0.3.5           glue_1.8.0            
# [37] RANN_2.6.1             reshape2_1.4.4         Rcpp_1.0.14            scattermore_1.2        spatstat.univar_3.0-0  vctrs_0.6.5           
# [43] spatstat.explore_3.3-1 nlme_3.1-165           progressr_0.14.0       lmtest_0.9-40          spatstat.random_3.3-1  stringr_1.5.1         
# [49] globals_0.16.3         mime_0.12              miniUI_0.1.1.1         lifecycle_1.0.4        irlba_2.3.5.1          goftest_1.2-3         
# [55] future_1.33.2          MASS_7.3-60.0.1        zoo_1.8-12             scales_1.3.0           ragg_1.3.2             promises_1.3.0        
# [61] spatstat.utils_3.0-5   parallel_4.2.0         RColorBrewer_1.1-3     reticulate_1.38.0      pbapply_1.7-2          gridExtra_2.3         
# [67] stringi_1.8.4          fastDummies_1.7.3      rlang_1.1.5            pkgconfig_2.0.3        systemfonts_1.1.0      matrixStats_1.3.0     
# [73] lattice_0.22-6         ROCR_1.0-11            purrr_1.0.4            tensor_1.5             patchwork_1.2.0        htmlwidgets_1.6.4     
# [79] labeling_0.4.3         cowplot_1.1.3          tidyselect_1.2.1       parallelly_1.37.1      RcppAnnoy_0.0.22       plyr_1.8.9            
# [85] magrittr_2.0.3         R6_2.6.1               generics_0.1.3         pillar_1.10.1          withr_3.0.2            fitdistrplus_1.2-1    
# [91] survival_3.7-0         abind_1.4-5            future.apply_1.11.2    KernSmooth_2.23-24     spatstat.geom_3.3-2    plotly_4.10.4         
# [97] grid_4.2.0             data.table_1.17.0      digest_0.6.36          xtable_1.8-4           httpuv_1.6.15          textshaping_0.4.0     
# [103] munsell_0.5.1          viridisLite_0.4.2 
```

#### NAc Dataset
```{r filename="NAc_dataset_plotting.R"}
# Setup ####
# Libraries
library(Seurat)
library(dplyr)
library(ggplot2)
library(tibble)
library(tidyr)

# Data
## Original NAc object
NAc_noXist <- readRDS("raw_data/NAc_Combo_Integrated.RDS")
NAc_Xist <- readRDS("processed_data/13_evaluation_NAc/NAc_Xist.RDS")

## NAc_Xist subsets
NAc_obj <- subset(NAc_noXist, cells = Cells(NAc_Xist))

# make metadata ordered factors
celltypes <- levels(NAc_obj$Combo_CellType) %>% rev()

NAc_obj$Combo_CellType <- factor(NAc_obj$Combo_CellType, levels = celltypes)
NAc_obj$Sex <- factor(NAc_obj$Sex, levels = c("Female", "Male"))

# Cluster summary plotting ####
# by cluster
NAc_obj@active.ident <- NAc_obj$Combo_CellType
all.dimplot.clusters <- DimPlot(NAc_obj, label = TRUE) + NoLegend()

# by sex
## all cells
NAc_obj@active.ident <- NAc_obj$Sex
all.dimplot.sex <- DimPlot(NAc_obj, shuffle = TRUE)

# Count cells
all.ncells.df <- table(NAc_obj$Combo_CellType) %>% # make a table of cell type counts
  data.frame() %>% # convert to dataframe
  rename("CellType" = "Var1",
         "Cells" = "Freq") %>% # rename columns
  mutate(CellType = factor(CellType, levels = celltypes)) # make cell type a factor

# CellType Cells
# 1         Drd1-MSN-1  5083
# 2         Drd1-MSN-2  2219
# 3         Drd2-MSN-1  5338
# 4         Drd2-MSN-2   490
# 5           Drd3-MSN   564
# 6           Grm8-MSN  2975
# 7          GABAergic  3079
# 8   Chat-Interneuron    84
# 9  Pvalb-Interneuron   724
# 10   Sst-Interneuron   403
# 11     Glutamatergic   680
# 12         Astrocyte  2893
# 13         Microglia  1503
# 14             Mural   128
# 15            Olig-1 10995
# 16    Polydendrocyte  2094

## save outputs
ggsave(plot = all.dimplot.clusters,
       file = "plots/dataset_plotting/NAc_all.UMAP.celltypes.pdf",
       device = "pdf",
       height = 10,
       width = 10)

ggsave(plot = all.dimplot.sex,
       file = "plots/dataset_plotting/NAc_all.UMAP.sex.pdf",
       device = "pdf",
       height = 10,
       width = 10)

# sessionInfo ####
sessionInfo()
# R version 4.2.0 (2022-04-22)
# Platform: x86_64-pc-linux-gnu (64-bit)
# Running under: Red Hat Enterprise Linux
# 
# Matrix products: default
# BLAS/LAPACK: /data/rc/apps/rc/software/FlexiBLAS/3.2.1-GCC-12.2.0/lib64/libflexiblas.so.3.2
# 
# locale:
#   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
# [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C                 
# [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
# 
# attached base packages:
#   [1] stats     graphics  grDevices utils     datasets  methods   base     
# 
# other attached packages:
#   [1] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1      dplyr_1.1.4        Seurat_5.2.1       SeuratObject_5.0.2
# [7] sp_2.1-4          
# 
# loaded via a namespace (and not attached):
#   [1] Rtsne_0.17             colorspace_2.1-0       deldir_2.0-4           ggridges_0.5.6         RcppHNSW_0.6.0        
# [6] rstudioapi_0.16.0      spatstat.data_3.1-2    listenv_0.9.1          farver_2.1.2           ggrepel_0.9.5         
# [11] RSpectra_0.16-1        codetools_0.2-20       splines_4.2.0          polyclip_1.10-6        spam_2.11-1           
# [16] jsonlite_1.8.8         ica_1.0-3              cluster_2.1.6          png_0.1-8              uwot_0.2.2            
# [21] shiny_1.8.1.1          sctransform_0.4.1      spatstat.sparse_3.1-0  compiler_4.2.0         httr_1.4.7            
# [26] Matrix_1.6-5           fastmap_1.2.0          lazyeval_0.2.2         cli_3.6.4              later_1.3.2           
# [31] htmltools_0.5.8.1      tools_4.2.0            igraph_2.0.3           dotCall64_1.1-1        gtable_0.3.5          
# [36] glue_1.8.0             RANN_2.6.1             reshape2_1.4.4         Rcpp_1.0.14            scattermore_1.2       
# [41] spatstat.univar_3.0-0  vctrs_0.6.5            spatstat.explore_3.3-1 nlme_3.1-165           progressr_0.14.0      
# [46] lmtest_0.9-40          spatstat.random_3.3-1  stringr_1.5.1          globals_0.16.3         mime_0.12             
# [51] miniUI_0.1.1.1         lifecycle_1.0.4        irlba_2.3.5.1          goftest_1.2-3          future_1.33.2         
# [56] MASS_7.3-60.0.1        zoo_1.8-12             scales_1.3.0           ragg_1.3.2             promises_1.3.0        
# [61] spatstat.utils_3.0-5   parallel_4.2.0         RColorBrewer_1.1-3     reticulate_1.38.0      pbapply_1.7-2         
# [66] gridExtra_2.3          stringi_1.8.4          fastDummies_1.7.3      rlang_1.1.5            pkgconfig_2.0.3       
# [71] systemfonts_1.1.0      matrixStats_1.3.0      lattice_0.22-6         ROCR_1.0-11            purrr_1.0.4           
# [76] tensor_1.5             patchwork_1.2.0        htmlwidgets_1.6.4      labeling_0.4.3         cowplot_1.1.3         
# [81] tidyselect_1.2.1       parallelly_1.37.1      RcppAnnoy_0.0.22       plyr_1.8.9             magrittr_2.0.3        
# [86] R6_2.6.1               generics_0.1.3         pillar_1.10.1          withr_3.0.2            fitdistrplus_1.2-1    
# [91] survival_3.7-0         abind_1.4-5            future.apply_1.11.2    KernSmooth_2.23-24     spatstat.geom_3.3-2   
# [96] plotly_4.10.4          grid_4.2.0             data.table_1.17.0      digest_0.6.36          xtable_1.8-4          
# [101] httpuv_1.6.15          textshaping_0.4.0      munsell_0.5.1          viridisLite_0.4.2  
```

